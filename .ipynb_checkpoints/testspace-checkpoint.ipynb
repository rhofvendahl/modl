{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading en_coref_md...\n",
      "...done\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-908328c939c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# MEMORYLESS FOR NOW; each change to text means a whole new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Set extensions later, for keeping track of which tokens are what\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-908328c939c1>\u001b[0m in \u001b[0;36mModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolved_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolved_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mpreprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_whitespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mpreprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_unicode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_contractions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_accents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "\n",
    "print('loading en_coref_md...')\n",
    "nlp = spacy.load('en_coref_md')\n",
    "print('...done')\n",
    "\n",
    "\n",
    "\n",
    "# for now assuming all names are unique identifiers\n",
    "class Person:\n",
    "    statements = []\n",
    "\n",
    "    def __init__(self, name, pronouns=None, refs=[], user=False):\n",
    "        self.name = name\n",
    "#         self.gender = gender\n",
    "        self.refs = refs\n",
    "        self.user = user\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# UPGRADE AT SOME POINT TO EXTRACT GENDER, ACCOUNT FOR CLUSTERS WITHOUT NAMES\n",
    "# UPGRADE TO INCLUDE I, USER\n",
    "\n",
    "# assumes names are unique identifiers\n",
    "# assumes misspellings are diff people\n",
    "\n",
    "# MEMORYLESS FOR NOW; each change to text means a whole new model\n",
    "# Set extensions later, for keeping track of which tokens are what\n",
    "class Model:\n",
    "    text = None\n",
    "    doc = None\n",
    "    people = []\n",
    "    resolved_text = None\n",
    "    resolved_doc = None\n",
    "\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.doc = self.get_doc()\n",
    "        self.people = self.get_people()\n",
    "        self.resolved_text = self.get_resolved()\n",
    "        self.resolved_doc = self.get_doc(self.resolved_text)\n",
    "\n",
    "    def get_doc(self, text=self.text):\n",
    "        preprocessed = textacy.preprocess.normalize_whitespace(text)\n",
    "        preprocessed = textacy.preprocess.preprocess_text(preprocessed, fix_unicode=True, no_contractions=True, no_accents=True)\n",
    "        doc = nlp(preprocessed)\n",
    "\n",
    "        # merge mentions into tokens for easy coref tracking, resolution\n",
    "        for cluster in doc._.coref_clusters:\n",
    "            for mention in cluster.mentions:\n",
    "                mention.merge()\n",
    "        return doc\n",
    "\n",
    "        def get_person_by_name(self, name):\n",
    "            for person in self.people:\n",
    "                if person.name == name:\n",
    "                    return person\n",
    "                    return None\n",
    "\n",
    "    def get_people(self, doc=self.doc):\n",
    "        namedrops = [ent for ent in doc.ents if ent.label_ == 'PERSON']\n",
    "        names = set([namedrop.text for namedrop in namedrops])\n",
    "        people = []\n",
    "\n",
    "        # for clusters that include namedrops\n",
    "        for cluster in doc._.coref_clusters:\n",
    "            name = None\n",
    "\n",
    "            for mention in cluster.mentions:\n",
    "                mention_text = mention.root.text\n",
    "                if mention_text in names:\n",
    "                    name = mention_text\n",
    "\n",
    "            if name != None:\n",
    "                person = self.get_person_by_name(name)\n",
    "                refs = [mention.head.i for mention in cluster.mentions]\n",
    "                if person == None:\n",
    "                    person = Person(name, refs=refs)\n",
    "                    people += [person]\n",
    "                else:\n",
    "                    person.refs += refs\n",
    "\n",
    "            # for named entities without clusters (single mentions)\n",
    "            for name_mention in name_mentions:\n",
    "                person = self.get_person_by_name(name_mention.text)\n",
    "                if person == None:\n",
    "                    person = Person(name_mention.text, refs=[name_mention.head.i])\n",
    "                    people += [person]\n",
    "        return people\n",
    "\n",
    "    def get_resolved(self, doc=self.doc):\n",
    "        token_texts = [token.text for token in doc]\n",
    "\n",
    "        for person in self.people:\n",
    "            for ref in person.refs:\n",
    "                resolved = person.name\n",
    "                if doc[ref].pos_ == 'ADJ':\n",
    "                    resolved += '\\'s'\n",
    "\n",
    "                token_texts[ref] = resolved\n",
    "        return ' '.join(token_texts)\n",
    "\n",
    "    # def update_people_statements(self, doc):\n",
    "    #     res = nlp(self.resolve_people(doc))\n",
    "    #\n",
    "    #     for person in model.people:\n",
    "    #         statements = []\n",
    "    #         for ref in person.refss:\n",
    "    #             head = ref.root.head\n",
    "    #             if head.pos_ == 'VERB':\n",
    "    #                 for statement in textacy.extract.semistructured_statements(res, person.name, head.lemma_):\n",
    "    #                     statements += [statement]\n",
    "    #         person.statements = list(set(statements))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
