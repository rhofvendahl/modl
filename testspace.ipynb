{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "\n",
    "print('loading en_coref_md...')\n",
    "nlp = spacy.load('en_coref_med')\n",
    "print('...done')\n",
    "\n",
    "\n",
    "\n",
    "# for now assuming all names are unique identifiers\n",
    "class Person:\n",
    "    statements = []\n",
    "\n",
    "    def __init__(self, name, pronouns=None, mentions=[], user=False):\n",
    "        self.name = name\n",
    "#         self.gender = gender\n",
    "        self.mentions = mentions\n",
    "        self.user = user\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# UPGRADE AT SOME POINT TO EXTRACT GENDER, ACCOUNT FOR CLUSTERS WITHOUT NAMES\n",
    "# UPGRADE TO INCLUDE I, USER\n",
    "\n",
    "# assumes names are unique identifiers\n",
    "# assumes misspellings are diff people\n",
    "\n",
    "# MEMORYLESS FOR NOW; each change to text means a whole new model\n",
    "# Set extensions later, for keeping track of which tokens are what\n",
    "class Model:\n",
    "    text = None\n",
    "    doc = None\n",
    "    people = []\n",
    "\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.doc = self.get_doc()\n",
    "        self.people = self.get_people()\n",
    "\n",
    "    def get_doc(self, text=self.text):\n",
    "        preprocessed = textacy.preprocess.normalize_whitespace(text)\n",
    "        preprocessed = textacy.preprocess.preprocess_text(preprocessed, fix_unicode=True, no_contractions=True, no_accents=True)\n",
    "        doc = nlp(preprocessed)\n",
    "\n",
    "        # merge mentions into tokens for easy coref tracking, resolution\n",
    "        for cluster in doc._.coref_clusters:\n",
    "            for mention in cluster.mentions:\n",
    "                mention.merge()\n",
    "        return doc\n",
    "\n",
    "    def get_people(self, doc=self.doc):\n",
    "        name_mentions = [ent for ent in doc.ents if ent.label_ == 'PERSON']\n",
    "        names = set([name_mention.text for name_mention in name_mentions])\n",
    "        people = []\n",
    "\n",
    "        # for clusters that includ ename mentions\n",
    "        for cluster in doc._.coref_clusters:\n",
    "            name = None\n",
    "\n",
    "            for mention in cluster.mentions:\n",
    "                keyword = mention.root.text\n",
    "                if keyword in names:\n",
    "                    name = keyword\n",
    "\n",
    "            if name != None:\n",
    "                person = self.get_person_by_name(name)\n",
    "                if person == None:\n",
    "                    person = Person(name, mentions=cluster.mentions)\n",
    "                    people += [person]\n",
    "                else:\n",
    "                    person.mentions += cluster.mentions\n",
    "\n",
    "            # for named entities without clusters (single mentions)\n",
    "            for name_mention in name_mentions:\n",
    "                person = self.get_person_by_name(name_mention.text)\n",
    "                if person == None:\n",
    "                    person = Person(name_mention.text, mentions=[name_mention])\n",
    "                    people += [person]\n",
    "        return people\n",
    "\n",
    "    def get_person_by_name(self, name):\n",
    "        for person in self.people:\n",
    "            if person.name == name:\n",
    "                return person\n",
    "                return None\n",
    "\n",
    "    def get_resolved(self, doc=self.doc):\n",
    "        tokens = [token.text for token in doc]\n",
    "\n",
    "        for person in self.people:\n",
    "            for mention in person.mentions:\n",
    "\n",
    "                # determine resolved value\n",
    "                resolved = person.name\n",
    "                if mention.root.pos == 'ADJ':\n",
    "                    resolved += '\\'s'\n",
    "\n",
    "                # set first token to resolved value\n",
    "                tokens[mention.start] = resolved\n",
    "\n",
    "                # set extra tokens in mention to blank\n",
    "                for i in range(mention.start+1, mention.end):\n",
    "                    tokens[i] = ''\n",
    "        return ' '.join([token for token in tokens if token != ''])\n",
    "\n",
    "    def update_people_statements(self, doc):\n",
    "        res = nlp(self.resolve_people(doc))\n",
    "\n",
    "        for person in model.people:\n",
    "            statements = []\n",
    "            for mention in person.mentions:\n",
    "                head = mention.root.head\n",
    "                if head.pos_ == 'VERB':\n",
    "                    for statement in textacy.extract.semistructured_statements(res, person.name, head.lemma_):\n",
    "                        statements += [statement]\n",
    "            person.statements = list(set(statements))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
