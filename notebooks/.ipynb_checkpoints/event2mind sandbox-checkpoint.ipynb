{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I guess I am feeling kinda tired. I feel overwhelmed, a bit, maybe hungry. I dunno. I find myself wanting something, but I'm not sure what it is. I feel stressed certainly, too much to do maybe? But I'm not totally sure what I should be doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(myself, wanting, something)\n"
     ]
    }
   ],
   "source": [
    "svo_triples = textacy.extract.subject_verb_object_triples(doc)\n",
    "\n",
    "for triple in svo_triples:\n",
    "    print(triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am feeling --> kinda tired\n",
      "I feel --> overwhelmed, a bit, maybe hungry\n",
      "I feel --> stressed certainly, too much to do maybe\n"
     ]
    }
   ],
   "source": [
    "# returns (entity, cue, fragment)\n",
    "statements = textacy.extract.semistructured_statements(doc, 'I', cue='feel')\n",
    "\n",
    "for entity, cue, fragment in statements:\n",
    "    print(entity, cue, '-->', fragment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent: I guess I am feeling kinda tired. \n",
      "verbs: [guess, feeling]\n",
      "I guess (I, guess, I am feeling kinda tired)\n",
      "I feeling (I, am feeling, kinda tired)\n",
      "I feeling (I, feel, overwhelmed, a bit, maybe hungry)\n",
      "I feeling (I, feel, stressed certainly, too much to do maybe)\n",
      "\n",
      "\n",
      "sent: I feel overwhelmed, a bit, maybe hungry. \n",
      "verbs: [feel]\n",
      "I feel (I, am feeling, kinda tired)\n",
      "I feel (I, feel, overwhelmed, a bit, maybe hungry)\n",
      "I feel (I, feel, stressed certainly, too much to do maybe)\n",
      "\n",
      "\n",
      "sent: I dunno. \n",
      "verbs: [dunno]\n",
      "\n",
      "\n",
      "sent: I find myself wanting something, but I'm not sure what it is. \n",
      "verbs: [find, wanting, 'm, is]\n",
      "I find (I, find, myself wanting something, but I'm not sure what it is)\n",
      "I 'm (I, 'm, not sure what it is)\n",
      "I 'm (I, 'm, not totally sure what I should be doing)\n",
      "\n",
      "\n",
      "sent: I feel stressed certainly, too much to do maybe? \n",
      "verbs: [feel, do]\n",
      "I feel (I, am feeling, kinda tired)\n",
      "I feel (I, feel, overwhelmed, a bit, maybe hungry)\n",
      "I feel (I, feel, stressed certainly, too much to do maybe)\n",
      "\n",
      "\n",
      "sent: But I'm not totally sure what I should be doing? \n",
      "verbs: ['m, doing]\n",
      "I 'm (I, 'm, not sure what it is)\n",
      "I 'm (I, 'm, not totally sure what I should be doing)\n",
      "\n",
      "\n",
      "(I, feel, stressed certainly, too much to do maybe)\n",
      "(I, 'm, not totally sure what I should be doing)\n",
      "(I, am feeling, kinda tired)\n",
      "(I, 'm, not sure what it is)\n",
      "(I, feel, overwhelmed, a bit, maybe hungry)\n",
      "(I, find, myself wanting something, but I'm not sure what it is)\n",
      "(I, guess, I am feeling kinda tired)\n"
     ]
    }
   ],
   "source": [
    "# get cues\n",
    "all_statements = []\n",
    "for sent in doc.sents:\n",
    "    verbs = textacy.spacier.utils.get_main_verbs_of_sent(sent)\n",
    "    print('sent:', sent, '\\nverbs:', verbs)\n",
    "    for verb in verbs:\n",
    "        objects = textacy.spacier.utils.get_objects_of_verb(verb)\n",
    "        subjects = textacy.spacier.utils.get_subjects_of_verb(verb)\n",
    "        for subject in subjects:\n",
    "            statements = textacy.extract.semistructured_statements(doc, subject.text, verb.lemma_)\n",
    "            for statement in statements:\n",
    "                print(subject, verb, statement)\n",
    "                all_statements += [statement]\n",
    "    \n",
    "    print('\\n')\n",
    "for statement in set(all_statements):\n",
    "    print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/05/2018 21:56:34 - INFO - allennlp.models.archival -   loading archive file https://s3-us-west-2.amazonaws.com/allennlp/models/decomposable-attention-elmo-2018.02.19.tar.gz from cache at /home/russell/.allennlp/cache/1dbdfb3ce5af46c5b83353727b579a5596d45a121d59199f1c838928a87e3796.21e6e14db76ce734b669577cc3046333c6bc853767246356b4a8b2c6a85249a8\n",
      "12/05/2018 21:56:34 - INFO - allennlp.models.archival -   extracting archive file /home/russell/.allennlp/cache/1dbdfb3ce5af46c5b83353727b579a5596d45a121d59199f1c838928a87e3796.21e6e14db76ce734b669577cc3046333c6bc853767246356b4a8b2c6a85249a8 to temp dir /tmp/tmpdvw280lq\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   type = default\n",
      "12/05/2018 21:56:42 - INFO - allennlp.data.vocabulary -   Loading token dictionary from /tmp/tmpdvw280lq/vocabulary.\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.model.Model'> from params {'initializer': [['.*linear_layers.*weight', {'type': 'xavier_normal'}], ['.*token_embedder_tokens\\\\._projection.*weight', {'type': 'xavier_normal'}]], 'type': 'decomposable_attention', 'aggregate_feedforward': {'activations': ['relu', 'linear'], 'dropout': [0.2, 0], 'hidden_dims': [200, 3], 'input_dim': 400, 'num_layers': 2}, 'similarity_function': {'type': 'dot_product'}, 'compare_feedforward': {'activations': 'relu', 'dropout': 0.2, 'hidden_dims': 200, 'input_dim': 2048, 'num_layers': 2}, 'attend_feedforward': {'activations': 'relu', 'dropout': 0.2, 'hidden_dims': 200, 'input_dim': 1024, 'num_layers': 2}, 'text_field_embedder': {'elmo': {'do_layer_norm': False, 'type': 'elmo_token_embedder', 'dropout': 0.2, 'options_file': '/tmp/tmpdvw280lq/fta/model.text_field_embedder.elmo.options_file', 'weight_file': '/tmp/tmpdvw280lq/fta/model.text_field_embedder.elmo.weight_file'}}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f8405bc7748>}\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.type = decomposable_attention\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.decomposable_attention.DecomposableAttention'> from params {'initializer': [['.*linear_layers.*weight', {'type': 'xavier_normal'}], ['.*token_embedder_tokens\\\\._projection.*weight', {'type': 'xavier_normal'}]], 'aggregate_feedforward': {'activations': ['relu', 'linear'], 'dropout': [0.2, 0], 'hidden_dims': [200, 3], 'input_dim': 400, 'num_layers': 2}, 'similarity_function': {'type': 'dot_product'}, 'compare_feedforward': {'activations': 'relu', 'dropout': 0.2, 'hidden_dims': 200, 'input_dim': 2048, 'num_layers': 2}, 'attend_feedforward': {'activations': 'relu', 'dropout': 0.2, 'hidden_dims': 200, 'input_dim': 1024, 'num_layers': 2}, 'text_field_embedder': {'elmo': {'do_layer_norm': False, 'type': 'elmo_token_embedder', 'dropout': 0.2, 'options_file': '/tmp/tmpdvw280lq/fta/model.text_field_embedder.elmo.options_file', 'weight_file': '/tmp/tmpdvw280lq/fta/model.text_field_embedder.elmo.weight_file'}}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f8405bc7748>}\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'elmo': {'do_layer_norm': False, 'type': 'elmo_token_embedder', 'dropout': 0.2, 'options_file': '/tmp/tmpdvw280lq/fta/model.text_field_embedder.elmo.options_file', 'weight_file': '/tmp/tmpdvw280lq/fta/model.text_field_embedder.elmo.weight_file'}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f8405bc7748>}\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.type = basic\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.embedder_to_indexer_map = None\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.allow_unmatched_keys = False\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.token_embedders = None\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'type': 'elmo_token_embedder', 'dropout': 0.2, 'options_file': '/tmp/tmpdvw280lq/fta/model.text_field_embedder.elmo.options_file', 'weight_file': '/tmp/tmpdvw280lq/fta/model.text_field_embedder.elmo.weight_file'} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f8405bc7748>}\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.elmo.type = elmo_token_embedder\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.elmo.options_file = /tmp/tmpdvw280lq/fta/model.text_field_embedder.elmo.options_file\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.elmo.weight_file = /tmp/tmpdvw280lq/fta/model.text_field_embedder.elmo.weight_file\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.elmo.requires_grad = False\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.elmo.do_layer_norm = False\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.elmo.dropout = 0.2\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.elmo.namespace_to_cache = None\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.elmo.projection_dim = None\n",
      "12/05/2018 21:56:42 - INFO - allennlp.common.params -   model.text_field_embedder.elmo.scalar_mix_parameters = None\n",
      "12/05/2018 21:56:42 - INFO - allennlp.modules.elmo -   Initializing ELMo\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.attend_feedforward.input_dim = 1024\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.attend_feedforward.num_layers = 2\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.attend_feedforward.hidden_dims = 200\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.attend_feedforward.activations = relu\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.attend_feedforward.dropout = 0.2\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.similarity_functions.similarity_function.SimilarityFunction'> from params {'type': 'dot_product'} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f8405bc7748>}\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.similarity_function.type = dot_product\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.similarity_functions.dot_product.DotProductSimilarity'> from params {} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f8405bc7748>}\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.similarity_function.scale_output = False\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.compare_feedforward.input_dim = 2048\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.compare_feedforward.num_layers = 2\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.compare_feedforward.hidden_dims = 200\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.compare_feedforward.activations = relu\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.compare_feedforward.dropout = 0.2\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.aggregate_feedforward.input_dim = 400\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.aggregate_feedforward.num_layers = 2\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.aggregate_feedforward.hidden_dims = [200, 3]\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.aggregate_feedforward.activations = ['relu', 'linear']\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.aggregate_feedforward.dropout = [0.2, 0]\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.initializer = [['.*linear_layers.*weight', {'type': 'xavier_normal'}], ['.*token_embedder_tokens\\\\._projection.*weight', {'type': 'xavier_normal'}]]\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.initializer.list.list.type = xavier_normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   model.initializer.list.list.type = xavier_normal\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "12/05/2018 21:56:56 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "12/05/2018 21:56:56 - INFO - allennlp.nn.initializers -   Initializing parameters\n",
      "12/05/2018 21:56:56 - INFO - allennlp.nn.initializers -   Initializing _attend_feedforward._module._linear_layers.0.weight using .*linear_layers.*weight intitializer\n",
      "12/05/2018 21:56:56 - INFO - allennlp.nn.initializers -   Initializing _attend_feedforward._module._linear_layers.1.weight using .*linear_layers.*weight intitializer\n",
      "12/05/2018 21:56:56 - INFO - allennlp.nn.initializers -   Initializing _compare_feedforward._module._linear_layers.0.weight using .*linear_layers.*weight intitializer\n",
      "12/05/2018 21:56:56 - INFO - allennlp.nn.initializers -   Initializing _compare_feedforward._module._linear_layers.1.weight using .*linear_layers.*weight intitializer\n",
      "12/05/2018 21:56:56 - INFO - allennlp.nn.initializers -   Initializing _aggregate_feedforward._linear_layers.0.weight using .*linear_layers.*weight intitializer\n",
      "12/05/2018 21:56:56 - INFO - allennlp.nn.initializers -   Initializing _aggregate_feedforward._linear_layers.1.weight using .*linear_layers.*weight intitializer\n",
      "12/05/2018 21:56:56 - WARNING - allennlp.nn.initializers -   Did not use initialization regex that was passed: .*token_embedder_tokens\\._projection.*weight\n",
      "12/05/2018 21:56:56 - INFO - allennlp.nn.initializers -   Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "12/05/2018 21:56:56 - INFO - allennlp.nn.initializers -      _aggregate_feedforward._linear_layers.0.bias\n",
      "12/05/2018 21:56:56 - INFO - allennlp.nn.initializers -      _aggregate_feedforward._linear_layers.1.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _attend_feedforward._module._linear_layers.0.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _attend_feedforward._module._linear_layers.1.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _compare_feedforward._module._linear_layers.0.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _compare_feedforward._module._linear_layers.1.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.1.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.1.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1\n",
      "12/05/2018 21:56:57 - INFO - allennlp.nn.initializers -      _text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'token_indexers': {'elmo': {'type': 'elmo_characters'}}, 'tokenizer': {'end_tokens': ['@@NULL@@']}, 'type': 'snli'} and extras {}\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.params -   dataset_reader.type = snli\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.dataset_readers.snli.SnliReader'> from params {'token_indexers': {'elmo': {'type': 'elmo_characters'}}, 'tokenizer': {'end_tokens': ['@@NULL@@']}} and extras {}\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'end_tokens': ['@@NULL@@']} and extras {}\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.params -   dataset_reader.tokenizer.type = word\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.tokenizers.word_tokenizer.WordTokenizer'> from params {'end_tokens': ['@@NULL@@']} and extras {}\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.params -   dataset_reader.tokenizer.start_tokens = None\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.params -   dataset_reader.tokenizer.end_tokens = ['@@NULL@@']\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras {}\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.params -   dataset_reader.token_indexers.elmo.type = elmo_characters\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras {}\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.params -   dataset_reader.token_indexers.elmo.namespace = elmo_characters\n",
      "12/05/2018 21:56:57 - INFO - allennlp.common.params -   dataset_reader.lazy = False\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors import Predictor\n",
    "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/decomposable-attention-elmo-2018.02.19.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_logits': [-3.391864776611328, 4.570619106292725, 0.9505535364151001],\n",
       " 'label_probs': [0.00033908773912116885,\n",
       "  0.9735872745513916,\n",
       "  0.02607356198132038],\n",
       " 'h2p_attention': [[0.6615484952926636,\n",
       "   0.03999358043074608,\n",
       "   0.04555582255125046,\n",
       "   0.046556826680898666,\n",
       "   0.032376978546381,\n",
       "   0.02884303592145443,\n",
       "   0.021681087091565132,\n",
       "   0.02199293114244938,\n",
       "   0.021933946758508682,\n",
       "   0.03280186280608177,\n",
       "   0.02464543841779232,\n",
       "   0.0220700204372406],\n",
       "  [2.6478128347662278e-05,\n",
       "   0.9997804164886475,\n",
       "   2.5384990294696763e-05,\n",
       "   2.803125425998587e-05,\n",
       "   1.5035763681225944e-05,\n",
       "   1.5200890629785135e-05,\n",
       "   2.0365438103908673e-05,\n",
       "   1.5323941624956205e-05,\n",
       "   1.667179458308965e-05,\n",
       "   3.005035614478402e-05,\n",
       "   1.3499801752914209e-05,\n",
       "   1.3597185898106545e-05],\n",
       "  [0.10203886777162552,\n",
       "   0.08704567700624466,\n",
       "   0.11516872048377991,\n",
       "   0.11659414321184158,\n",
       "   0.0897686704993248,\n",
       "   0.1088109016418457,\n",
       "   0.06201941892504692,\n",
       "   0.06663387268781662,\n",
       "   0.06219317018985748,\n",
       "   0.07818535715341568,\n",
       "   0.0593428835272789,\n",
       "   0.052198376506567],\n",
       "  [0.0004895933088846505,\n",
       "   0.0005661703762598336,\n",
       "   0.0014663741458207369,\n",
       "   0.9835996627807617,\n",
       "   0.003986356779932976,\n",
       "   0.0008538846741430461,\n",
       "   0.0008042860426940024,\n",
       "   0.004030915908515453,\n",
       "   0.000624869717285037,\n",
       "   0.002379189943894744,\n",
       "   0.0006751827313564718,\n",
       "   0.0005234954296611249],\n",
       "  [0.02180355414748192,\n",
       "   0.016224386170506477,\n",
       "   0.04582870751619339,\n",
       "   0.32416868209838867,\n",
       "   0.1262902319431305,\n",
       "   0.21321798861026764,\n",
       "   0.03501936420798302,\n",
       "   0.09745176136493683,\n",
       "   0.036249496042728424,\n",
       "   0.04630831629037857,\n",
       "   0.022747211158275604,\n",
       "   0.014690198004245758],\n",
       "  [0.01745988056063652,\n",
       "   0.012007005512714386,\n",
       "   0.03334576636552811,\n",
       "   0.23861074447631836,\n",
       "   0.06420435011386871,\n",
       "   0.42332977056503296,\n",
       "   0.03817636892199516,\n",
       "   0.050691068172454834,\n",
       "   0.05518278479576111,\n",
       "   0.03998453542590141,\n",
       "   0.016478458419442177,\n",
       "   0.010529308579862118],\n",
       "  [0.010657047852873802,\n",
       "   0.011342254467308521,\n",
       "   0.013355554081499577,\n",
       "   0.39848199486732483,\n",
       "   0.026157716289162636,\n",
       "   0.050147585570812225,\n",
       "   0.36920735239982605,\n",
       "   0.02936599962413311,\n",
       "   0.03243587911128998,\n",
       "   0.04311087727546692,\n",
       "   0.008368291892111301,\n",
       "   0.00736935855820775],\n",
       "  [0.012434241361916065,\n",
       "   0.013259582221508026,\n",
       "   0.03426486626267433,\n",
       "   0.24050143361091614,\n",
       "   0.13842594623565674,\n",
       "   0.37977859377861023,\n",
       "   0.06643011420965195,\n",
       "   0.05420059710741043,\n",
       "   0.014995560981333256,\n",
       "   0.025156904011964798,\n",
       "   0.01212186086922884,\n",
       "   0.008430331014096737],\n",
       "  [0.025600627064704895,\n",
       "   0.02177058905363083,\n",
       "   0.05209308862686157,\n",
       "   0.08083993941545486,\n",
       "   0.0719628632068634,\n",
       "   0.5535196661949158,\n",
       "   0.05518198758363724,\n",
       "   0.037947289645671844,\n",
       "   0.030034935101866722,\n",
       "   0.040441691875457764,\n",
       "   0.01738293468952179,\n",
       "   0.013224351219832897],\n",
       "  [0.0034482465125620365,\n",
       "   0.0038895425386726856,\n",
       "   0.005236065946519375,\n",
       "   0.013813172467052937,\n",
       "   0.010430196300148964,\n",
       "   0.05077805370092392,\n",
       "   0.641498327255249,\n",
       "   0.01323755457997322,\n",
       "   0.16897264122962952,\n",
       "   0.08184266090393066,\n",
       "   0.0035076595377177,\n",
       "   0.0033459344413131475],\n",
       "  [0.011839332059025764,\n",
       "   0.009265673346817493,\n",
       "   0.020825976505875587,\n",
       "   0.4289425313472748,\n",
       "   0.027788354083895683,\n",
       "   0.02105570212006569,\n",
       "   0.014683406800031662,\n",
       "   0.3304857909679413,\n",
       "   0.05788344889879227,\n",
       "   0.0527602918446064,\n",
       "   0.017025265842676163,\n",
       "   0.00744414608925581],\n",
       "  [0.027381373569369316,\n",
       "   0.024950889870524406,\n",
       "   0.05205394700169563,\n",
       "   0.4092806279659271,\n",
       "   0.08168795704841614,\n",
       "   0.0769209936261177,\n",
       "   0.02724587544798851,\n",
       "   0.16947263479232788,\n",
       "   0.047082576900720596,\n",
       "   0.05163945257663727,\n",
       "   0.02144119143486023,\n",
       "   0.010842563584446907],\n",
       "  [0.0038758176378905773,\n",
       "   0.003917417023330927,\n",
       "   0.005418309476226568,\n",
       "   0.045663487166166306,\n",
       "   0.007978193461894989,\n",
       "   0.009805173613131046,\n",
       "   0.012987712398171425,\n",
       "   0.11252029985189438,\n",
       "   0.21147406101226807,\n",
       "   0.5791746377944946,\n",
       "   0.004015128128230572,\n",
       "   0.003169688628986478],\n",
       "  [0.07595512270927429,\n",
       "   0.06700103729963303,\n",
       "   0.08602173626422882,\n",
       "   0.13264940679073334,\n",
       "   0.0768849328160286,\n",
       "   0.08079946041107178,\n",
       "   0.07029906660318375,\n",
       "   0.09581216424703598,\n",
       "   0.08089634776115417,\n",
       "   0.074249267578125,\n",
       "   0.0905224159359932,\n",
       "   0.06890902668237686],\n",
       "  [0.08349008858203888,\n",
       "   0.08230611681938171,\n",
       "   0.08249524235725403,\n",
       "   0.0853073000907898,\n",
       "   0.07970943301916122,\n",
       "   0.0837709978222847,\n",
       "   0.08443307131528854,\n",
       "   0.08118802309036255,\n",
       "   0.08668394386768341,\n",
       "   0.0874016061425209,\n",
       "   0.08157685399055481,\n",
       "   0.08163739740848541]],\n",
       " 'p2h_attention': [[0.5873391032218933,\n",
       "   0.037481389939785004,\n",
       "   0.036728233098983765,\n",
       "   0.01829739846289158,\n",
       "   0.028163855895400047,\n",
       "   0.031889576464891434,\n",
       "   0.026729749515652657,\n",
       "   0.027614938095211983,\n",
       "   0.03713584318757057,\n",
       "   0.02042875997722149,\n",
       "   0.034058839082717896,\n",
       "   0.05014196038246155,\n",
       "   0.02343931421637535,\n",
       "   0.0210875291377306,\n",
       "   0.019463635981082916],\n",
       "  [2.508237594156526e-05,\n",
       "   0.999733567237854,\n",
       "   2.2132628146209754e-05,\n",
       "   1.4946935152693186e-05,\n",
       "   1.4804178135818802e-05,\n",
       "   1.5491494195885025e-05,\n",
       "   2.0095949366805144e-05,\n",
       "   2.0802033759537153e-05,\n",
       "   2.2308173356577754e-05,\n",
       "   1.6277719623758458e-05,\n",
       "   1.8829146938514896e-05,\n",
       "   3.227626802981831e-05,\n",
       "   1.6735255485400558e-05,\n",
       "   1.3140176633896772e-05,\n",
       "   1.3554149518313352e-05],\n",
       "  [0.05465352162718773,\n",
       "   0.04855705797672272,\n",
       "   0.056016504764556885,\n",
       "   0.07405351102352142,\n",
       "   0.07999254763126373,\n",
       "   0.0822991207242012,\n",
       "   0.04526546597480774,\n",
       "   0.10283025354146957,\n",
       "   0.1021103709936142,\n",
       "   0.04191756993532181,\n",
       "   0.08095712214708328,\n",
       "   0.12880918383598328,\n",
       "   0.044278454035520554,\n",
       "   0.0322718508541584,\n",
       "   0.025987526401877403],\n",
       "  [0.0009891841327771544,\n",
       "   0.0009495936101302505,\n",
       "   0.001004332909360528,\n",
       "   0.879708468914032,\n",
       "   0.010020802728831768,\n",
       "   0.010429514572024345,\n",
       "   0.02391846291720867,\n",
       "   0.012782299891114235,\n",
       "   0.0028063070494681597,\n",
       "   0.0019584111869335175,\n",
       "   0.02953033149242401,\n",
       "   0.0179363414645195,\n",
       "   0.006608717143535614,\n",
       "   0.00088133366080001,\n",
       "   0.00047592856572009623],\n",
       "  [0.021002642810344696,\n",
       "   0.01555121410638094,\n",
       "   0.023608563467860222,\n",
       "   0.10885298252105713,\n",
       "   0.11919141560792923,\n",
       "   0.08568055927753448,\n",
       "   0.04793670400977135,\n",
       "   0.22462216019630432,\n",
       "   0.07627135515213013,\n",
       "   0.04514884203672409,\n",
       "   0.0584084689617157,\n",
       "   0.10929856449365616,\n",
       "   0.035253044217824936,\n",
       "   0.01559625193476677,\n",
       "   0.013577163219451904],\n",
       "  [0.007228714879602194,\n",
       "   0.0060742199420928955,\n",
       "   0.011056041345000267,\n",
       "   0.00900836382061243,\n",
       "   0.07774664461612701,\n",
       "   0.21826252341270447,\n",
       "   0.035505931824445724,\n",
       "   0.23809383809566498,\n",
       "   0.2266567349433899,\n",
       "   0.08492054045200348,\n",
       "   0.01709878444671631,\n",
       "   0.0397634282708168,\n",
       "   0.0167390089482069,\n",
       "   0.0063324240036308765,\n",
       "   0.005512842908501625],\n",
       "  [0.0035782784689217806,\n",
       "   0.005359055008739233,\n",
       "   0.004149807151407003,\n",
       "   0.0055876621045172215,\n",
       "   0.008408895693719387,\n",
       "   0.012961878441274166,\n",
       "   0.17214486002922058,\n",
       "   0.027425561100244522,\n",
       "   0.014880097471177578,\n",
       "   0.7064885497093201,\n",
       "   0.007852272130548954,\n",
       "   0.009274972602725029,\n",
       "   0.014600914902985096,\n",
       "   0.003628138452768326,\n",
       "   0.0036590411327779293],\n",
       "  [0.007103194482624531,\n",
       "   0.007891187444329262,\n",
       "   0.008725148625671864,\n",
       "   0.054802581667900085,\n",
       "   0.04579288512468338,\n",
       "   0.03368080407381058,\n",
       "   0.02679453045129776,\n",
       "   0.04378972575068474,\n",
       "   0.0200247373431921,\n",
       "   0.02852955460548401,\n",
       "   0.34585878252983093,\n",
       "   0.11289872974157333,\n",
       "   0.24754595756530762,\n",
       "   0.009676819667220116,\n",
       "   0.006885323207825422],\n",
       "  [0.0065566846169531345,\n",
       "   0.007946044206619263,\n",
       "   0.0075373295694589615,\n",
       "   0.007862917147576809,\n",
       "   0.015765480697155,\n",
       "   0.03393528610467911,\n",
       "   0.02739201858639717,\n",
       "   0.011213157325983047,\n",
       "   0.014669311232864857,\n",
       "   0.33705487847328186,\n",
       "   0.05606571584939957,\n",
       "   0.029029978439211845,\n",
       "   0.43060502409935,\n",
       "   0.007562020793557167,\n",
       "   0.00680405693128705],\n",
       "  [0.00604318268597126,\n",
       "   0.00882710050791502,\n",
       "   0.00583982327952981,\n",
       "   0.018451131880283356,\n",
       "   0.012412630952894688,\n",
       "   0.015154428780078888,\n",
       "   0.022438034415245056,\n",
       "   0.011593696661293507,\n",
       "   0.01217340212315321,\n",
       "   0.10061518102884293,\n",
       "   0.0314955934882164,\n",
       "   0.019623102620244026,\n",
       "   0.7268270254135132,\n",
       "   0.0042776064947247505,\n",
       "   0.004228129982948303],\n",
       "  [0.05502630025148392,\n",
       "   0.048057641834020615,\n",
       "   0.05371672287583351,\n",
       "   0.06345729529857635,\n",
       "   0.07389234751462936,\n",
       "   0.07568860054016113,\n",
       "   0.052783865481615067,\n",
       "   0.06770184636116028,\n",
       "   0.06341211497783661,\n",
       "   0.05225980281829834,\n",
       "   0.1231694370508194,\n",
       "   0.09874189645051956,\n",
       "   0.06106431409716606,\n",
       "   0.06320204585790634,\n",
       "   0.04782582074403763],\n",
       "  [0.06751631200313568,\n",
       "   0.06632179766893387,\n",
       "   0.06473962217569351,\n",
       "   0.06741329282522202,\n",
       "   0.06538397073745728,\n",
       "   0.0662652850151062,\n",
       "   0.06368929892778397,\n",
       "   0.06451314687728882,\n",
       "   0.0660991445183754,\n",
       "   0.06830303370952606,\n",
       "   0.07378979027271271,\n",
       "   0.06841585785150528,\n",
       "   0.06605063378810883,\n",
       "   0.06592094898223877,\n",
       "   0.06557781249284744]],\n",
       " 'premise_tokens': ['Two',\n",
       "  'women',\n",
       "  'are',\n",
       "  'wandering',\n",
       "  'along',\n",
       "  'the',\n",
       "  'shore',\n",
       "  'drinking',\n",
       "  'iced',\n",
       "  'tea',\n",
       "  '.',\n",
       "  '@@NULL@@'],\n",
       " 'hypothesis_tokens': ['Two',\n",
       "  'women',\n",
       "  'are',\n",
       "  'sitting',\n",
       "  'on',\n",
       "  'a',\n",
       "  'blanket',\n",
       "  'near',\n",
       "  'some',\n",
       "  'rocks',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'politics',\n",
       "  '.',\n",
       "  '@@NULL@@']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predictor.predict(\n",
    "  hypothesis=\"Two women are sitting on a blanket near some rocks talking about politics.\",\n",
    "  premise=\"Two women are wandering along the shore drinking iced tea.\"\n",
    ")\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction['premise_tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I guess I am feeling kinda tired. I feel overwhelmed, a bit, maybe hungry. I dunno. I find myself wanting something, but I'm not sure what it is. I feel stressed certainly, too much to do maybe? But I'm not totally sure what I should be doing? Now it's a lot later and it's really time for me to get to bed...but a part of me wants to stay up, nonetheless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([], columns=['premise', 'hypothesis', 'entailment', 'contradiction', 'neutral', 'e+c'])\n",
    "i = 0\n",
    "for premise in doc.sents:\n",
    "#     entailment, contradiction, neutral = None\n",
    "    for hypothesis in doc.sents:\n",
    "        if (premise != hypothesis):\n",
    "            prediction = predictor.predict(hypothesis=hypothesis.text, premise=premise.text)\n",
    "            entailment, contradiction, neutral = prediction['label_probs']\n",
    "            results.loc[i] = [premise.text, hypothesis.text, entailment, contradiction, neutral, (entailment + (1 - contradiction)) / 2]\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>entailment</th>\n",
       "      <th>contradiction</th>\n",
       "      <th>neutral</th>\n",
       "      <th>e+c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>0.956455</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.042311</td>\n",
       "      <td>0.977611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>0.908410</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.086143</td>\n",
       "      <td>0.951481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I guess I am feeling kinda tired.</td>\n",
       "      <td>I dunno.</td>\n",
       "      <td>0.904193</td>\n",
       "      <td>0.053517</td>\n",
       "      <td>0.042290</td>\n",
       "      <td>0.925338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>I dunno.</td>\n",
       "      <td>0.912021</td>\n",
       "      <td>0.070635</td>\n",
       "      <td>0.017344</td>\n",
       "      <td>0.920693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I feel overwhelmed, a bit, maybe hungry.</td>\n",
       "      <td>I guess I am feeling kinda tired.</td>\n",
       "      <td>0.836310</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.162772</td>\n",
       "      <td>0.917696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I feel overwhelmed, a bit, maybe hungry.</td>\n",
       "      <td>I dunno.</td>\n",
       "      <td>0.867386</td>\n",
       "      <td>0.043489</td>\n",
       "      <td>0.089125</td>\n",
       "      <td>0.911948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>I guess I am feeling kinda tired.</td>\n",
       "      <td>0.781964</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.216260</td>\n",
       "      <td>0.890094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>0.755611</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.236309</td>\n",
       "      <td>0.873766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>0.767259</td>\n",
       "      <td>0.020967</td>\n",
       "      <td>0.211775</td>\n",
       "      <td>0.873146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>but a part of me wants to stay up, nonetheless</td>\n",
       "      <td>0.768105</td>\n",
       "      <td>0.025418</td>\n",
       "      <td>0.206478</td>\n",
       "      <td>0.871344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>I guess I am feeling kinda tired.</td>\n",
       "      <td>0.739140</td>\n",
       "      <td>0.012235</td>\n",
       "      <td>0.248626</td>\n",
       "      <td>0.863452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I guess I am feeling kinda tired.</td>\n",
       "      <td>I feel overwhelmed, a bit, maybe hungry.</td>\n",
       "      <td>0.725396</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.271786</td>\n",
       "      <td>0.861288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>but a part of me wants to stay up, nonetheless</td>\n",
       "      <td>0.735134</td>\n",
       "      <td>0.026731</td>\n",
       "      <td>0.238136</td>\n",
       "      <td>0.854201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>I feel overwhelmed, a bit, maybe hungry.</td>\n",
       "      <td>0.727070</td>\n",
       "      <td>0.022596</td>\n",
       "      <td>0.250334</td>\n",
       "      <td>0.852237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I feel overwhelmed, a bit, maybe hungry.</td>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>0.717547</td>\n",
       "      <td>0.035562</td>\n",
       "      <td>0.246891</td>\n",
       "      <td>0.840992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I feel overwhelmed, a bit, maybe hungry.</td>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>0.678346</td>\n",
       "      <td>0.013190</td>\n",
       "      <td>0.308464</td>\n",
       "      <td>0.832578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>Now it's a lot later</td>\n",
       "      <td>0.659936</td>\n",
       "      <td>0.050289</td>\n",
       "      <td>0.289775</td>\n",
       "      <td>0.804823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I guess I am feeling kinda tired.</td>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>0.604333</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.389258</td>\n",
       "      <td>0.798962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>but a part of me wants to stay up, nonetheless</td>\n",
       "      <td>0.682849</td>\n",
       "      <td>0.088772</td>\n",
       "      <td>0.228379</td>\n",
       "      <td>0.797039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>I dunno.</td>\n",
       "      <td>0.762202</td>\n",
       "      <td>0.184278</td>\n",
       "      <td>0.053520</td>\n",
       "      <td>0.788962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>I feel overwhelmed, a bit, maybe hungry.</td>\n",
       "      <td>0.567174</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.429359</td>\n",
       "      <td>0.781854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>but a part of me wants to stay up, nonetheless</td>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>0.584167</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.385075</td>\n",
       "      <td>0.776704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>I guess I am feeling kinda tired.</td>\n",
       "      <td>0.566095</td>\n",
       "      <td>0.020107</td>\n",
       "      <td>0.413798</td>\n",
       "      <td>0.772994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>0.589310</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>0.366994</td>\n",
       "      <td>0.772807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>I feel overwhelmed, a bit, maybe hungry.</td>\n",
       "      <td>0.571464</td>\n",
       "      <td>0.038498</td>\n",
       "      <td>0.390039</td>\n",
       "      <td>0.766483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>but a part of me wants to stay up, nonetheless</td>\n",
       "      <td>Now it's a lot later</td>\n",
       "      <td>0.566257</td>\n",
       "      <td>0.038796</td>\n",
       "      <td>0.394947</td>\n",
       "      <td>0.763730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>but a part of me wants to stay up, nonetheless</td>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>0.538478</td>\n",
       "      <td>0.052767</td>\n",
       "      <td>0.408755</td>\n",
       "      <td>0.742856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>I dunno.</td>\n",
       "      <td>0.715452</td>\n",
       "      <td>0.238567</td>\n",
       "      <td>0.045980</td>\n",
       "      <td>0.738443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>Now it's a lot later</td>\n",
       "      <td>0.548609</td>\n",
       "      <td>0.073129</td>\n",
       "      <td>0.378262</td>\n",
       "      <td>0.737740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I guess I am feeling kinda tired.</td>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>0.474978</td>\n",
       "      <td>0.064011</td>\n",
       "      <td>0.461011</td>\n",
       "      <td>0.705483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.081693</td>\n",
       "      <td>0.458307</td>\n",
       "      <td>0.689153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>and it's really time for me to get to bed...</td>\n",
       "      <td>but a part of me wants to stay up, nonetheless</td>\n",
       "      <td>0.523283</td>\n",
       "      <td>0.235219</td>\n",
       "      <td>0.241498</td>\n",
       "      <td>0.644032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>Now it's a lot later</td>\n",
       "      <td>0.381097</td>\n",
       "      <td>0.175689</td>\n",
       "      <td>0.443214</td>\n",
       "      <td>0.602704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I feel overwhelmed, a bit, maybe hungry.</td>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>0.373584</td>\n",
       "      <td>0.176693</td>\n",
       "      <td>0.449723</td>\n",
       "      <td>0.598446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Now it's a lot later</td>\n",
       "      <td>but a part of me wants to stay up, nonetheless</td>\n",
       "      <td>0.386267</td>\n",
       "      <td>0.217766</td>\n",
       "      <td>0.395967</td>\n",
       "      <td>0.584250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I feel overwhelmed, a bit, maybe hungry.</td>\n",
       "      <td>but a part of me wants to stay up, nonetheless</td>\n",
       "      <td>0.329103</td>\n",
       "      <td>0.298593</td>\n",
       "      <td>0.372304</td>\n",
       "      <td>0.515255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I guess I am feeling kinda tired.</td>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>0.269745</td>\n",
       "      <td>0.259522</td>\n",
       "      <td>0.470732</td>\n",
       "      <td>0.505112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>but a part of me wants to stay up, nonetheless</td>\n",
       "      <td>I dunno.</td>\n",
       "      <td>0.285518</td>\n",
       "      <td>0.384351</td>\n",
       "      <td>0.330131</td>\n",
       "      <td>0.450584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>and it's really time for me to get to bed...</td>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>0.234756</td>\n",
       "      <td>0.339052</td>\n",
       "      <td>0.426192</td>\n",
       "      <td>0.447852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Now it's a lot later</td>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>0.247193</td>\n",
       "      <td>0.352285</td>\n",
       "      <td>0.400522</td>\n",
       "      <td>0.447454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>and it's really time for me to get to bed...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.486933</td>\n",
       "      <td>0.479734</td>\n",
       "      <td>0.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Now it's a lot later</td>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>0.045921</td>\n",
       "      <td>0.508242</td>\n",
       "      <td>0.445838</td>\n",
       "      <td>0.268840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>and it's really time for me to get to bed...</td>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>0.073138</td>\n",
       "      <td>0.543047</td>\n",
       "      <td>0.383816</td>\n",
       "      <td>0.265046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>and it's really time for me to get to bed...</td>\n",
       "      <td>0.019627</td>\n",
       "      <td>0.526356</td>\n",
       "      <td>0.454018</td>\n",
       "      <td>0.246635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I dunno.</td>\n",
       "      <td>Now it's a lot later</td>\n",
       "      <td>0.038739</td>\n",
       "      <td>0.573239</td>\n",
       "      <td>0.388022</td>\n",
       "      <td>0.232750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>and it's really time for me to get to bed...</td>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>0.102812</td>\n",
       "      <td>0.712032</td>\n",
       "      <td>0.185157</td>\n",
       "      <td>0.195390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Now it's a lot later</td>\n",
       "      <td>I dunno.</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.634602</td>\n",
       "      <td>0.344303</td>\n",
       "      <td>0.193247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>and it's really time for me to get to bed...</td>\n",
       "      <td>I dunno.</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>0.898486</td>\n",
       "      <td>0.083470</td>\n",
       "      <td>0.059780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I dunno.</td>\n",
       "      <td>and it's really time for me to get to bed...</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.894391</td>\n",
       "      <td>0.104787</td>\n",
       "      <td>0.053215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I guess I am feeling kinda tired.</td>\n",
       "      <td>and it's really time for me to get to bed...</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>0.925812</td>\n",
       "      <td>0.071030</td>\n",
       "      <td>0.038673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              premise  \\\n",
       "43   But I'm not totally sure what I should be doing?   \n",
       "44   But I'm not totally sure what I should be doing?   \n",
       "1                   I guess I am feeling kinda tired.   \n",
       "34   I feel stressed certainly, too much to do maybe?   \n",
       "8            I feel overwhelmed, a bit, maybe hungry.   \n",
       "9            I feel overwhelmed, a bit, maybe hungry.   \n",
       "32   I feel stressed certainly, too much to do maybe?   \n",
       "35   I feel stressed certainly, too much to do maybe?   \n",
       "27  I find myself wanting something, but I'm not s...   \n",
       "47   But I'm not totally sure what I should be doing?   \n",
       "40   But I'm not totally sure what I should be doing?   \n",
       "0                   I guess I am feeling kinda tired.   \n",
       "31  I find myself wanting something, but I'm not s...   \n",
       "41   But I'm not totally sure what I should be doing?   \n",
       "10           I feel overwhelmed, a bit, maybe hungry.   \n",
       "11           I feel overwhelmed, a bit, maybe hungry.   \n",
       "29  I find myself wanting something, but I'm not s...   \n",
       "3                   I guess I am feeling kinda tired.   \n",
       "39   I feel stressed certainly, too much to do maybe?   \n",
       "42   But I'm not totally sure what I should be doing?   \n",
       "33   I feel stressed certainly, too much to do maybe?   \n",
       "67     but a part of me wants to stay up, nonetheless   \n",
       "24  I find myself wanting something, but I'm not s...   \n",
       "36   I feel stressed certainly, too much to do maybe?   \n",
       "25  I find myself wanting something, but I'm not s...   \n",
       "70     but a part of me wants to stay up, nonetheless   \n",
       "68     but a part of me wants to stay up, nonetheless   \n",
       "26  I find myself wanting something, but I'm not s...   \n",
       "37   I feel stressed certainly, too much to do maybe?   \n",
       "2                   I guess I am feeling kinda tired.   \n",
       "28  I find myself wanting something, but I'm not s...   \n",
       "63       and it's really time for me to get to bed...   \n",
       "45   But I'm not totally sure what I should be doing?   \n",
       "12           I feel overwhelmed, a bit, maybe hungry.   \n",
       "55                               Now it's a lot later   \n",
       "15           I feel overwhelmed, a bit, maybe hungry.   \n",
       "4                   I guess I am feeling kinda tired.   \n",
       "66     but a part of me wants to stay up, nonetheless   \n",
       "59       and it's really time for me to get to bed...   \n",
       "51                               Now it's a lot later   \n",
       "30  I find myself wanting something, but I'm not s...   \n",
       "53                               Now it's a lot later   \n",
       "61       and it's really time for me to get to bed...   \n",
       "46   But I'm not totally sure what I should be doing?   \n",
       "21                                           I dunno.   \n",
       "60       and it's really time for me to get to bed...   \n",
       "50                               Now it's a lot later   \n",
       "58       and it's really time for me to get to bed...   \n",
       "22                                           I dunno.   \n",
       "6                   I guess I am feeling kinda tired.   \n",
       "\n",
       "                                           hypothesis  entailment  \\\n",
       "43  I find myself wanting something, but I'm not s...    0.956455   \n",
       "44   I feel stressed certainly, too much to do maybe?    0.908410   \n",
       "1                                            I dunno.    0.904193   \n",
       "34                                           I dunno.    0.912021   \n",
       "8                   I guess I am feeling kinda tired.    0.836310   \n",
       "9                                            I dunno.    0.867386   \n",
       "32                  I guess I am feeling kinda tired.    0.781964   \n",
       "35  I find myself wanting something, but I'm not s...    0.755611   \n",
       "27   I feel stressed certainly, too much to do maybe?    0.767259   \n",
       "47     but a part of me wants to stay up, nonetheless    0.768105   \n",
       "40                  I guess I am feeling kinda tired.    0.739140   \n",
       "0            I feel overwhelmed, a bit, maybe hungry.    0.725396   \n",
       "31     but a part of me wants to stay up, nonetheless    0.735134   \n",
       "41           I feel overwhelmed, a bit, maybe hungry.    0.727070   \n",
       "10  I find myself wanting something, but I'm not s...    0.717547   \n",
       "11   I feel stressed certainly, too much to do maybe?    0.678346   \n",
       "29                               Now it's a lot later    0.659936   \n",
       "3    I feel stressed certainly, too much to do maybe?    0.604333   \n",
       "39     but a part of me wants to stay up, nonetheless    0.682849   \n",
       "42                                           I dunno.    0.762202   \n",
       "33           I feel overwhelmed, a bit, maybe hungry.    0.567174   \n",
       "67  I find myself wanting something, but I'm not s...    0.584167   \n",
       "24                  I guess I am feeling kinda tired.    0.566095   \n",
       "36   But I'm not totally sure what I should be doing?    0.589310   \n",
       "25           I feel overwhelmed, a bit, maybe hungry.    0.571464   \n",
       "70                               Now it's a lot later    0.566257   \n",
       "68   I feel stressed certainly, too much to do maybe?    0.538478   \n",
       "26                                           I dunno.    0.715452   \n",
       "37                               Now it's a lot later    0.548609   \n",
       "2   I find myself wanting something, but I'm not s...    0.474978   \n",
       "28   But I'm not totally sure what I should be doing?    0.460000   \n",
       "63     but a part of me wants to stay up, nonetheless    0.523283   \n",
       "45                               Now it's a lot later    0.381097   \n",
       "12   But I'm not totally sure what I should be doing?    0.373584   \n",
       "55     but a part of me wants to stay up, nonetheless    0.386267   \n",
       "15     but a part of me wants to stay up, nonetheless    0.329103   \n",
       "4    But I'm not totally sure what I should be doing?    0.269745   \n",
       "66                                           I dunno.    0.285518   \n",
       "59  I find myself wanting something, but I'm not s...    0.234756   \n",
       "51  I find myself wanting something, but I'm not s...    0.247193   \n",
       "30       and it's really time for me to get to bed...    0.033333   \n",
       "53   But I'm not totally sure what I should be doing?    0.045921   \n",
       "61   But I'm not totally sure what I should be doing?    0.073138   \n",
       "46       and it's really time for me to get to bed...    0.019627   \n",
       "21                               Now it's a lot later    0.038739   \n",
       "60   I feel stressed certainly, too much to do maybe?    0.102812   \n",
       "50                                           I dunno.    0.021096   \n",
       "58                                           I dunno.    0.018045   \n",
       "22       and it's really time for me to get to bed...    0.000822   \n",
       "6        and it's really time for me to get to bed...    0.003158   \n",
       "\n",
       "    contradiction   neutral       e+c  \n",
       "43       0.001234  0.042311  0.977611  \n",
       "44       0.005447  0.086143  0.951481  \n",
       "1        0.053517  0.042290  0.925338  \n",
       "34       0.070635  0.017344  0.920693  \n",
       "8        0.000918  0.162772  0.917696  \n",
       "9        0.043489  0.089125  0.911948  \n",
       "32       0.001776  0.216260  0.890094  \n",
       "35       0.008080  0.236309  0.873766  \n",
       "27       0.020967  0.211775  0.873146  \n",
       "47       0.025418  0.206478  0.871344  \n",
       "40       0.012235  0.248626  0.863452  \n",
       "0        0.002819  0.271786  0.861288  \n",
       "31       0.026731  0.238136  0.854201  \n",
       "41       0.022596  0.250334  0.852237  \n",
       "10       0.035562  0.246891  0.840992  \n",
       "11       0.013190  0.308464  0.832578  \n",
       "29       0.050289  0.289775  0.804823  \n",
       "3        0.006409  0.389258  0.798962  \n",
       "39       0.088772  0.228379  0.797039  \n",
       "42       0.184278  0.053520  0.788962  \n",
       "33       0.003467  0.429359  0.781854  \n",
       "67       0.030758  0.385075  0.776704  \n",
       "24       0.020107  0.413798  0.772994  \n",
       "36       0.043696  0.366994  0.772807  \n",
       "25       0.038498  0.390039  0.766483  \n",
       "70       0.038796  0.394947  0.763730  \n",
       "68       0.052767  0.408755  0.742856  \n",
       "26       0.238567  0.045980  0.738443  \n",
       "37       0.073129  0.378262  0.737740  \n",
       "2        0.064011  0.461011  0.705483  \n",
       "28       0.081693  0.458307  0.689153  \n",
       "63       0.235219  0.241498  0.644032  \n",
       "45       0.175689  0.443214  0.602704  \n",
       "12       0.176693  0.449723  0.598446  \n",
       "55       0.217766  0.395967  0.584250  \n",
       "15       0.298593  0.372304  0.515255  \n",
       "4        0.259522  0.470732  0.505112  \n",
       "66       0.384351  0.330131  0.450584  \n",
       "59       0.339052  0.426192  0.447852  \n",
       "51       0.352285  0.400522  0.447454  \n",
       "30       0.486933  0.479734  0.273200  \n",
       "53       0.508242  0.445838  0.268840  \n",
       "61       0.543047  0.383816  0.265046  \n",
       "46       0.526356  0.454018  0.246635  \n",
       "21       0.573239  0.388022  0.232750  \n",
       "60       0.712032  0.185157  0.195390  \n",
       "50       0.634602  0.344303  0.193247  \n",
       "58       0.898486  0.083470  0.059780  \n",
       "22       0.894391  0.104787  0.053215  \n",
       "6        0.925812  0.071030  0.038673  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='e+c', ascending=False).loc[results['neutral'] < .5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = 'I feel stressed'\n",
    "\n",
    "results = pd.DataFrame([], columns=['premise', 'hypothesis', 'entailment', 'contradiction', 'neutral'])\n",
    "i = 0\n",
    "for premise in doc.sents:\n",
    "    prediction = predictor.predict(hypothesis=hypothesis, premise=premise.text)\n",
    "    entailment, contradiction, neutral = prediction['label_probs']\n",
    "    results.loc[i] = [premise.text, hypothesis, entailment, contradiction, neutral]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>entailment</th>\n",
       "      <th>contradiction</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I feel stressed certainly, too much to do maybe?</td>\n",
       "      <td>I feel stressed</td>\n",
       "      <td>0.985132</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.014467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I guess I am feeling kinda tired.</td>\n",
       "      <td>I feel stressed</td>\n",
       "      <td>0.936851</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.060882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I feel overwhelmed, a bit, maybe hungry.</td>\n",
       "      <td>I feel stressed</td>\n",
       "      <td>0.933847</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.063966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I find myself wanting something, but I'm not s...</td>\n",
       "      <td>I feel stressed</td>\n",
       "      <td>0.833155</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.162525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>But I'm not totally sure what I should be doing?</td>\n",
       "      <td>I feel stressed</td>\n",
       "      <td>0.769592</td>\n",
       "      <td>0.041008</td>\n",
       "      <td>0.189401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I dunno.</td>\n",
       "      <td>I feel stressed</td>\n",
       "      <td>0.493208</td>\n",
       "      <td>0.287141</td>\n",
       "      <td>0.219651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>but a part of me wants to stay up, nonetheless</td>\n",
       "      <td>I feel stressed</td>\n",
       "      <td>0.293085</td>\n",
       "      <td>0.115519</td>\n",
       "      <td>0.591396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and it's really time for me to get to bed...</td>\n",
       "      <td>I feel stressed</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.353283</td>\n",
       "      <td>0.537717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Now it's a lot later</td>\n",
       "      <td>I feel stressed</td>\n",
       "      <td>0.081763</td>\n",
       "      <td>0.259905</td>\n",
       "      <td>0.658333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise       hypothesis  \\\n",
       "4   I feel stressed certainly, too much to do maybe?  I feel stressed   \n",
       "0                  I guess I am feeling kinda tired.  I feel stressed   \n",
       "1           I feel overwhelmed, a bit, maybe hungry.  I feel stressed   \n",
       "3  I find myself wanting something, but I'm not s...  I feel stressed   \n",
       "5   But I'm not totally sure what I should be doing?  I feel stressed   \n",
       "2                                           I dunno.  I feel stressed   \n",
       "8     but a part of me wants to stay up, nonetheless  I feel stressed   \n",
       "7       and it's really time for me to get to bed...  I feel stressed   \n",
       "6                               Now it's a lot later  I feel stressed   \n",
       "\n",
       "   entailment  contradiction   neutral  \n",
       "4    0.985132       0.000401  0.014467  \n",
       "0    0.936851       0.002266  0.060882  \n",
       "1    0.933847       0.002187  0.063966  \n",
       "3    0.833155       0.004319  0.162525  \n",
       "5    0.769592       0.041008  0.189401  \n",
       "2    0.493208       0.287141  0.219651  \n",
       "8    0.293085       0.115519  0.591396  \n",
       "7    0.109000       0.353283  0.537717  \n",
       "6    0.081763       0.259905  0.658333  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='entailment', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(shape):\n",
    "    nlp = spacy.load('en_vectors_web_lg')\n",
    "    nlp.add_pipe(KerasSimilarityShim.load(nlp.path / 'similarity', nlp, shape[0]))\n",
    "\n",
    "    doc1 = nlp(u'The king of France is bald.')\n",
    "    doc2 = nlp(u'France has no king.')\n",
    "\n",
    "    print(\"Sentence 1:\", doc1)\n",
    "    print(\"Sentence 2:\", doc2)\n",
    "\n",
    "    entailment_type, confidence = doc1.similarity(doc2)\n",
    "    print(\"Entailment type:\", entailment_type, \"(Confidence:\", confidence, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy.vsm import Vectorizer\n",
    "vectorizer = Vectorizer(\n",
    "    tf_type='linear', apply_idf=True, idf_type='smooth', norm='l2',\n",
    "    min_df=3, max_df=0.95, max_n_terms=100000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = textacy.tm.TopicModel('nmf', n_topics=20)\n",
    "model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy.keyterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sure', 0.17393909018065556),\n",
       " ('overwhelmed', 0.1291297332498814),\n",
       " ('time', 0.12848449534695075),\n",
       " ('bit', 0.12152651186559832),\n",
       " ('lot', 0.12055447304217964),\n",
       " ('hungry', 0.11759733293982846),\n",
       " ('tired', 0.07154722366605952),\n",
       " ('bed', 0.0712721534037857),\n",
       " ('stressed', 0.06594898630506062)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = textacy.keyterms.key_terms_from_semantic_network(doc)\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sure', 0.33850825516726607),\n",
       " ('stressed', 0.1517767729454664),\n",
       " ('bed', 0.1484936700017998),\n",
       " ('time', 0.0968496495027204),\n",
       " ('lot', 0.07202910699164278),\n",
       " ('hungry', 0.07058674833731196),\n",
       " ('bit', 0.051420957354160426),\n",
       " ('overwhelmed', 0.03964374936267677),\n",
       " ('tired', 0.030691090336955648)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = textacy.keyterms.sgrank(doc)\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I guess I am feeling kinda tired. I feel overwhelmed, a bit, maybe hungry. I dunno. I find myself wanting something, but I'm not sure what it is. I feel stressed certainly, too much to do maybe? But I'm not totally sure what I should be doing? Now it's a lot later and it's really time for me to get to bed...but a part of me wants to stay up, nonetheless\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy.lexicon_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/05/2018 21:16:22 - INFO - textacy.lexicon_methods -   Downloaded DepecheMood (4MB) from https://github.com/marcoguerini/DepecheMood/releases/download/v1.0/DepecheMood_V1.0.zip and wrote it to data\n"
     ]
    }
   ],
   "source": [
    "textacy.lexicon_methods.download_depechemood(data_dir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'AFRAID': 0.1103335419756097,\n",
       "             'AMUSED': 0.14808456209756102,\n",
       "             'ANGRY': 0.10694153351219511,\n",
       "             'ANNOYED': 0.12443051617073168,\n",
       "             'DONT_CARE': 0.13096818899999998,\n",
       "             'HAPPY': 0.11531756726829266,\n",
       "             'INSPIRED': 0.14843126431707318,\n",
       "             'SAD': 0.11549282553658531})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textacy.lexicon_methods.emotional_valence(words=[word for word in doc], dm_data_dir='data/DepecheMood_V1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "# predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/event2mind-2018.09.17.tar.gz\")\n",
    "# predictor.predict(\n",
    "#   source=\"PersonX drops a hint\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ":py:class:`Model` is an abstract class representing\n",
    "an AllenNLP model.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict, Union, List, Set\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "from allennlp.common.params import Params\n",
    "from allennlp.common.registrable import Registrable\n",
    "from allennlp.data import Instance, Vocabulary\n",
    "from allennlp.data.dataset import Batch\n",
    "from allennlp.nn import util\n",
    "from allennlp.nn.regularizers import RegularizerApplicator\n",
    "\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n",
    "\n",
    "# When training a model, many sets of weights are saved. By default we want to\n",
    "# save/load this set of weights.\n",
    "_DEFAULT_WEIGHTS = \"best.th\"\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module, Registrable):\n",
    "    \"\"\"\n",
    "    This abstract class represents a model to be trained. Rather than relying completely\n",
    "    on the Pytorch Module, we modify the output spec of ``forward`` to be a dictionary.\n",
    "    Models built using this API are still compatible with other pytorch models and can\n",
    "    be used naturally as modules within other models - outputs are dictionaries, which\n",
    "    can be unpacked and passed into other layers. One caveat to this is that if you\n",
    "    wish to use an AllenNLP model inside a Container (such as nn.Sequential), you must\n",
    "    interleave the models with a wrapper module which unpacks the dictionary into\n",
    "    a list of tensors.\n",
    "    In order for your model to be trained using the :class:`~allennlp.training.Trainer`\n",
    "    api, the output dictionary of your Model must include a \"loss\" key, which will be\n",
    "    optimised during the training process.\n",
    "    Finally, you can optionally implement :func:`Model.get_metrics` in order to make use\n",
    "    of early stopping and best-model serialization based on a validation metric in\n",
    "    :class:`~allennlp.training.Trainer`. Metrics that begin with \"_\" will not be logged\n",
    "    to the progress bar by :class:`~allennlp.training.Trainer`.\n",
    "    \"\"\"\n",
    "    _warn_for_unseparable_batches: Set[str] = set()\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab: Vocabulary,\n",
    "                 regularizer: RegularizerApplicator = None) -> None:\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self._regularizer = regularizer\n",
    "\n",
    "    def get_regularization_penalty(self) -> Union[float, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Computes the regularization penalty for the model.\n",
    "        Returns 0 if the model was not configured to use regularization.\n",
    "        \"\"\"\n",
    "        if self._regularizer is None:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return self._regularizer(self)\n",
    "\n",
    "    def get_parameters_for_histogram_tensorboard_logging( # pylint: disable=invalid-name\n",
    "            self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Returns the name of model parameters used for logging histograms to tensorboard.\n",
    "        \"\"\"\n",
    "        return [name for name, _ in self.named_parameters()]\n",
    "\n",
    "    def forward(self, *inputs) -> Dict[str, torch.Tensor]:  # pylint: disable=arguments-differ\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the model. In addition, to facilitate easy training,\n",
    "        this method is designed to compute a loss function defined by a user.\n",
    "        The input is comprised of everything required to perform a\n",
    "        training update, `including` labels - you define the signature here!\n",
    "        It is down to the user to ensure that inference can be performed\n",
    "        without the presence of these labels. Hence, any inputs not available at\n",
    "        inference time should only be used inside a conditional block.\n",
    "        The intended sketch of this method is as follows::\n",
    "            def forward(self, input1, input2, targets=None):\n",
    "                ....\n",
    "                ....\n",
    "                output1 = self.layer1(input1)\n",
    "                output2 = self.layer2(input2)\n",
    "                output_dict = {\"output1\": output1, \"output2\": output2}\n",
    "                if targets is not None:\n",
    "                    # Function returning a scalar torch.Tensor, defined by the user.\n",
    "                    loss = self._compute_loss(output1, output2, targets)\n",
    "                    output_dict[\"loss\"] = loss\n",
    "                return output_dict\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs:\n",
    "            Tensors comprising everything needed to perform a training update, `including` labels,\n",
    "            which should be optional (i.e have a default value of ``None``).  At inference time,\n",
    "            simply pass the relevant inputs, not including the labels.\n",
    "        Returns\n",
    "        -------\n",
    "        output_dict: ``Dict[str, torch.Tensor]``\n",
    "            The outputs from the model. In order to train a model using the\n",
    "            :class:`~allennlp.training.Trainer` api, you must provide a \"loss\" key pointing to a\n",
    "            scalar ``torch.Tensor`` representing the loss to be optimized.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward_on_instance(self, instance: Instance) -> Dict[str, numpy.ndarray]:\n",
    "        \"\"\"\n",
    "        Takes an :class:`~allennlp.data.instance.Instance`, which typically has raw text in it,\n",
    "        converts that text into arrays using this model's :class:`Vocabulary`, passes those arrays\n",
    "        through :func:`self.forward()` and :func:`self.decode()` (which by default does nothing)\n",
    "        and returns the result.  Before returning the result, we convert any\n",
    "        ``torch.Tensors`` into numpy arrays and remove the batch dimension.\n",
    "        \"\"\"\n",
    "        return self.forward_on_instances([instance])[0]\n",
    "\n",
    "    def forward_on_instances(self,\n",
    "                             instances: List[Instance]) -> List[Dict[str, numpy.ndarray]]:\n",
    "        \"\"\"\n",
    "        Takes a list of  :class:`~allennlp.data.instance.Instance`s, converts that text into\n",
    "        arrays using this model's :class:`Vocabulary`, passes those arrays through\n",
    "        :func:`self.forward()` and :func:`self.decode()` (which by default does nothing)\n",
    "        and returns the result.  Before returning the result, we convert any\n",
    "        ``torch.Tensors`` into numpy arrays and separate the\n",
    "        batched output into a list of individual dicts per instance. Note that typically\n",
    "        this will be faster on a GPU (and conditionally, on a CPU) than repeated calls to\n",
    "        :func:`forward_on_instance`.\n",
    "        Parameters\n",
    "        ----------\n",
    "        instances : List[Instance], required\n",
    "            The instances to run the model on.\n",
    "        cuda_device : int, required\n",
    "            The GPU device to use.  -1 means use the CPU.\n",
    "        Returns\n",
    "        -------\n",
    "        A list of the models output for each instance.\n",
    "        \"\"\"\n",
    "        batch_size = len(instances)\n",
    "        with torch.no_grad():\n",
    "            cuda_device = self._get_prediction_device()\n",
    "            dataset = Batch(instances)\n",
    "            dataset.index_instances(self.vocab)\n",
    "            model_input = util.move_to_device(dataset.as_tensor_dict(), cuda_device)\n",
    "            outputs = self.decode(self(**model_input))\n",
    "\n",
    "            instance_separated_output: List[Dict[str, numpy.ndarray]] = [{} for _ in dataset.instances]\n",
    "            for name, output in list(outputs.items()):\n",
    "                if isinstance(output, torch.Tensor):\n",
    "                    # NOTE(markn): This is a hack because 0-dim pytorch tensors are not iterable.\n",
    "                    # This occurs with batch size 1, because we still want to include the loss in that case.\n",
    "                    if output.dim() == 0:\n",
    "                        output = output.unsqueeze(0)\n",
    "\n",
    "                    if output.size(0) != batch_size:\n",
    "                        self._maybe_warn_for_unseparable_batches(name)\n",
    "                        continue\n",
    "                    output = output.detach().cpu().numpy()\n",
    "                elif len(output) != batch_size:\n",
    "                    self._maybe_warn_for_unseparable_batches(name)\n",
    "                    continue\n",
    "                outputs[name] = output\n",
    "                for instance_output, batch_element in zip(instance_separated_output, output):\n",
    "                    instance_output[name] = batch_element\n",
    "            return instance_separated_output\n",
    "\n",
    "    def decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Takes the result of :func:`forward` and runs inference / decoding / whatever\n",
    "        post-processing you need to do your model.  The intent is that ``model.forward()`` should\n",
    "        produce potentials or probabilities, and then ``model.decode()`` can take those results and\n",
    "        run some kind of beam search or constrained inference or whatever is necessary.  This does\n",
    "        not handle all possible decoding use cases, but it at least handles simple kinds of\n",
    "        decoding.\n",
    "        This method `modifies` the input dictionary, and also `returns` the same dictionary.\n",
    "        By default in the base class we do nothing.  If your model has some special decoding step,\n",
    "        override this method.\n",
    "        \"\"\"\n",
    "        # pylint: disable=no-self-use\n",
    "        return output_dict\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Returns a dictionary of metrics. This method will be called by\n",
    "        :class:`allennlp.training.Trainer` in order to compute and use model metrics for early\n",
    "        stopping and model serialization.  We return an empty dictionary here rather than raising\n",
    "        as it is not required to implement metrics for a new model.  A boolean `reset` parameter is\n",
    "        passed, as frequently a metric accumulator will have some state which should be reset\n",
    "        between epochs. This is also compatible with :class:`~allennlp.training.Metric`s. Metrics\n",
    "        should be populated during the call to ``forward``, with the\n",
    "        :class:`~allennlp.training.Metric` handling the accumulation of the metric until this\n",
    "        method is called.\n",
    "        \"\"\"\n",
    "        # pylint: disable=unused-argument,no-self-use\n",
    "        return {}\n",
    "\n",
    "    def _get_prediction_device(self) -> int:\n",
    "        \"\"\"\n",
    "        This method checks the device of the model parameters to determine the cuda_device\n",
    "        this model should be run on for predictions.  If there are no parameters, it returns -1.\n",
    "        Returns\n",
    "        -------\n",
    "        The cuda device this model should run on for predictions.\n",
    "        \"\"\"\n",
    "        devices = {util.get_device_of(param) for param in self.parameters()}\n",
    "\n",
    "        if len(devices) > 1:\n",
    "            devices_string = \", \".join(str(x) for x in devices)\n",
    "            raise ConfigurationError(f\"Parameters have mismatching cuda_devices: {devices_string}\")\n",
    "        elif len(devices) == 1:\n",
    "            return devices.pop()\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def _maybe_warn_for_unseparable_batches(self, output_key: str):\n",
    "        \"\"\"\n",
    "        This method warns once if a user implements a model which returns a dictionary with\n",
    "        values which we are unable to split back up into elements of the batch. This is controlled\n",
    "        by a class attribute ``_warn_for_unseperable_batches`` because it would be extremely verbose\n",
    "        otherwise.\n",
    "        \"\"\"\n",
    "        if  output_key not in self._warn_for_unseparable_batches:\n",
    "            logger.warning(f\"Encountered the {output_key} key in the model's return dictionary which \"\n",
    "                           \"couldn't be split by the batch size. Key will be ignored.\")\n",
    "            # We only want to warn once for this key,\n",
    "            # so we set this to false so we don't warn again.\n",
    "            self._warn_for_unseparable_batches.add(output_key)\n",
    "\n",
    "    @classmethod\n",
    "    def _load(cls,\n",
    "              config: Params,\n",
    "              serialization_dir: str,\n",
    "              weights_file: str = None,\n",
    "              cuda_device: int = -1) -> 'Model':\n",
    "        \"\"\"\n",
    "        Instantiates an already-trained model, based on the experiment\n",
    "        configuration and some optional overrides.\n",
    "        \"\"\"\n",
    "        weights_file = weights_file or os.path.join(serialization_dir, _DEFAULT_WEIGHTS)\n",
    "\n",
    "        # Load vocabulary from file\n",
    "        vocab_dir = os.path.join(serialization_dir, 'vocabulary')\n",
    "        # If the config specifies a vocabulary subclass, we need to use it.\n",
    "        vocab_params = config.get(\"vocabulary\", Params({}))\n",
    "        vocab_choice = vocab_params.pop_choice(\"type\", Vocabulary.list_available(), True)\n",
    "        vocab = Vocabulary.by_name(vocab_choice).from_files(vocab_dir)\n",
    "\n",
    "        model_params = config.get('model')\n",
    "\n",
    "        # The experiment config tells us how to _train_ a model, including where to get pre-trained\n",
    "        # embeddings from.  We're now _loading_ the model, so those embeddings will already be\n",
    "        # stored in our weights.  We don't need any pretrained weight file anymore, and we don't\n",
    "        # want the code to look for it, so we remove it from the parameters here.\n",
    "        remove_pretrained_embedding_params(model_params)\n",
    "        model = Model.from_params(vocab=vocab, params=model_params)\n",
    "        model_state = torch.load(weights_file, map_location=util.device_mapping(cuda_device))\n",
    "        model_state = {}\n",
    "        model.load_state_dict(model_state)\n",
    "\n",
    "        # Force model to cpu or gpu, as appropriate, to make sure that the embeddings are\n",
    "        # in sync with the weights\n",
    "        if cuda_device >= 0:\n",
    "            model.cuda(cuda_device)\n",
    "        else:\n",
    "            model.cpu()\n",
    "\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls,\n",
    "             config: Params,\n",
    "             serialization_dir: str,\n",
    "             weights_file: str = None,\n",
    "             cuda_device: int = -1) -> 'Model':\n",
    "        \"\"\"\n",
    "        Instantiates an already-trained model, based on the experiment\n",
    "        configuration and some optional overrides.\n",
    "        Parameters\n",
    "        ----------\n",
    "        config: Params\n",
    "            The configuration that was used to train the model. It should definitely\n",
    "            have a `model` section, and should probably have a `trainer` section\n",
    "            as well.\n",
    "        serialization_dir: str = None\n",
    "            The directory containing the serialized weights, parameters, and vocabulary\n",
    "            of the model.\n",
    "        weights_file: str = None\n",
    "            By default we load the weights from `best.th` in the serialization\n",
    "            directory, but you can override that value here.\n",
    "        cuda_device: int = -1\n",
    "            By default we load the model on the CPU, but if you want to load it\n",
    "            for GPU usage you can specify the id of your GPU here\n",
    "        Returns\n",
    "        -------\n",
    "        model: Model\n",
    "            The model specified in the configuration, loaded with the serialized\n",
    "            vocabulary and the trained weights.\n",
    "        \"\"\"\n",
    "\n",
    "        # Peak at the class of the model.\n",
    "        model_type = config[\"model\"][\"type\"]\n",
    "\n",
    "        # Load using an overridable _load method.\n",
    "        # This allows subclasses of Model to override _load.\n",
    "        # pylint: disable=protected-access\n",
    "        return cls.by_name(model_type)._load(config, serialization_dir, weights_file, cuda_device)\n",
    "\n",
    "\n",
    "def remove_pretrained_embedding_params(params: Params):\n",
    "    keys = params.keys()\n",
    "    if 'pretrained_file' in keys:\n",
    "        del params['pretrained_file']\n",
    "    for value in params.values():\n",
    "        if isinstance(value, Params):\n",
    "            remove_pretrained_embedding_params(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper functions for archiving models and restoring archived models.\n",
    "\"\"\"\n",
    "\n",
    "from typing import NamedTuple, Dict, Any\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.common.params import Params, unflatten, with_fallback, parse_overrides\n",
    "from allennlp.models.model import _DEFAULT_WEIGHTS#Model, _DEFAULT_WEIGHTS\n",
    "\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n",
    "\n",
    "# An archive comprises a Model and its experimental config\n",
    "Archive = NamedTuple(\"Archive\", [(\"model\", Model), (\"config\", Params)])\n",
    "\n",
    "# We archive a model by creating a tar.gz file with its weights, config, and vocabulary.\n",
    "#\n",
    "# We also may include other arbitrary files in the archive. In this case we store\n",
    "# the mapping { flattened_path -> filename } in ``files_to_archive.json`` and the files\n",
    "# themselves under the path ``fta/`` .\n",
    "#\n",
    "# These constants are the *known names* under which we archive them.\n",
    "CONFIG_NAME = \"config.json\"\n",
    "_WEIGHTS_NAME = \"weights.th\"\n",
    "_FTA_NAME = \"files_to_archive.json\"\n",
    "\n",
    "# def archive_model(serialization_dir: str,\n",
    "#                   weights: str = _DEFAULT_WEIGHTS,\n",
    "#                   files_to_archive: Dict[str, str] = None) -> None:\n",
    "#     \"\"\"\n",
    "#     Archive the model weights, its training configuration, and its\n",
    "#     vocabulary to `model.tar.gz`. Include the additional ``files_to_archive``\n",
    "#     if provided.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     serialization_dir: ``str``\n",
    "#         The directory where the weights and vocabulary are written out.\n",
    "#     weights: ``str``, optional (default=_DEFAULT_WEIGHTS)\n",
    "#         Which weights file to include in the archive. The default is ``best.th``.\n",
    "#     files_to_archive: ``Dict[str, str]``, optional (default=None)\n",
    "#         A mapping {flattened_key -> filename} of supplementary files to include\n",
    "#         in the archive. That is, if you wanted to include ``params['model']['weights']``\n",
    "#         then you would specify the key as `\"model.weights\"`.\n",
    "#     \"\"\"\n",
    "#     weights_file = os.path.join(serialization_dir, weights)\n",
    "#     if not os.path.exists(weights_file):\n",
    "#         logger.error(\"weights file %s does not exist, unable to archive model\", weights_file)\n",
    "#         return\n",
    "\n",
    "#     config_file = os.path.join(serialization_dir, CONFIG_NAME)\n",
    "#     if not os.path.exists(config_file):\n",
    "#         logger.error(\"config file %s does not exist, unable to archive model\", config_file)\n",
    "\n",
    "#     # If there are files we want to archive, write out the mapping\n",
    "#     # so that we can use it during de-archiving.\n",
    "#     if files_to_archive:\n",
    "#         fta_filename = os.path.join(serialization_dir, _FTA_NAME)\n",
    "#         with open(fta_filename, 'w') as fta_file:\n",
    "#             fta_file.write(json.dumps(files_to_archive))\n",
    "\n",
    "\n",
    "#     archive_file = os.path.join(serialization_dir, \"model.tar.gz\")\n",
    "#     logger.info(\"archiving weights and vocabulary to %s\", archive_file)\n",
    "#     with tarfile.open(archive_file, 'w:gz') as archive:\n",
    "#         archive.add(config_file, arcname=CONFIG_NAME)\n",
    "#         archive.add(weights_file, arcname=_WEIGHTS_NAME)\n",
    "#         archive.add(os.path.join(serialization_dir, \"vocabulary\"),\n",
    "#                     arcname=\"vocabulary\")\n",
    "\n",
    "#         # If there are supplemental files to archive:\n",
    "#         if files_to_archive:\n",
    "#             # Archive the { flattened_key -> original_filename } mapping.\n",
    "#             archive.add(fta_filename, arcname=_FTA_NAME)\n",
    "#             # And add each requested file to the archive.\n",
    "#             for key, filename in files_to_archive.items():\n",
    "#                 archive.add(filename, arcname=f\"fta/{key}\")\n",
    "\n",
    "def load_archive(archive_file: str,\n",
    "                 cuda_device: int = -1,\n",
    "                 overrides: str = \"\",\n",
    "                 weights_file: str = None) -> Archive:\n",
    "    \"\"\"\n",
    "    Instantiates an Archive from an archived `tar.gz` file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    archive_file: ``str``\n",
    "        The archive file to load the model from.\n",
    "    weights_file: ``str``, optional (default = None)\n",
    "        The weights file to use.  If unspecified, weights.th in the archive_file will be used.\n",
    "    cuda_device: ``int``, optional (default = -1)\n",
    "        If `cuda_device` is >= 0, the model will be loaded onto the\n",
    "        corresponding GPU. Otherwise it will be loaded onto the CPU.\n",
    "    overrides: ``str``, optional (default = \"\")\n",
    "        JSON overrides to apply to the unarchived ``Params`` object.\n",
    "    \"\"\"\n",
    "    # redirect to the cache, if necessary\n",
    "    resolved_archive_file = cached_path(archive_file)\n",
    "\n",
    "    if resolved_archive_file == archive_file:\n",
    "        logger.info(f\"loading archive file {archive_file}\")\n",
    "    else:\n",
    "        logger.info(f\"loading archive file {archive_file} from cache at {resolved_archive_file}\")\n",
    "\n",
    "    tempdir = None\n",
    "    if os.path.isdir(resolved_archive_file):\n",
    "        serialization_dir = resolved_archive_file\n",
    "    else:\n",
    "        # Extract archive to temp dir\n",
    "        tempdir = tempfile.mkdtemp()\n",
    "        logger.info(f\"extracting archive file {resolved_archive_file} to temp dir {tempdir}\")\n",
    "        with tarfile.open(resolved_archive_file, 'r:gz') as archive:\n",
    "            archive.extractall(tempdir)\n",
    "\n",
    "        serialization_dir = tempdir\n",
    "\n",
    "    # Check for supplemental files in archive\n",
    "    fta_filename = os.path.join(serialization_dir, _FTA_NAME)\n",
    "    if os.path.exists(fta_filename):\n",
    "        with open(fta_filename, 'r') as fta_file:\n",
    "            files_to_archive = json.loads(fta_file.read())\n",
    "\n",
    "        # Add these replacements to overrides\n",
    "        replacements_dict: Dict[str, Any] = {}\n",
    "        for key, _ in files_to_archive.items():\n",
    "            replacement_filename = os.path.join(serialization_dir, f\"fta/{key}\")\n",
    "            replacements_dict[key] = replacement_filename\n",
    "\n",
    "        overrides_dict = parse_overrides(overrides)\n",
    "        combined_dict = with_fallback(preferred=unflatten(replacements_dict), fallback=overrides_dict)\n",
    "        overrides = json.dumps(combined_dict)\n",
    "\n",
    "    # Load config\n",
    "    config = Params.from_file(os.path.join(serialization_dir, CONFIG_NAME), overrides)\n",
    "    config.loading_from_archive = True\n",
    "\n",
    "    if weights_file:\n",
    "        weights_path = weights_file\n",
    "    else:\n",
    "        weights_path = os.path.join(serialization_dir, _WEIGHTS_NAME)\n",
    "\n",
    "        \n",
    "    # Instantiate model. Use a duplicate of the config, as it will get consumed.\n",
    "    model = Model.load(config.duplicate(),\n",
    "                       weights_file=weights_path,\n",
    "                       serialization_dir=serialization_dir,\n",
    "                       cuda_device=cuda_device)\n",
    "\n",
    "    if tempdir:\n",
    "        # Clean up temp dir\n",
    "        shutil.rmtree(tempdir)\n",
    "\n",
    "    return Archive(model=model, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigurationError",
     "evalue": "'Cannot register event2mind as Model; name already in use for Event2Mind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-daa9d5bc0e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"event2mind\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mEvent2Mind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \"\"\"\n\u001b[1;32m     26\u001b[0m     \u001b[0mThis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mEvent2Mind\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mtakes\u001b[0m \u001b[0man\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/allennlp/common/registrable.py\u001b[0m in \u001b[0;36madd_subclass_to_registry\u001b[0;34m(subclass)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 message = \"Cannot register %s as %s; name already in use for %s\" % (\n\u001b[1;32m     48\u001b[0m                         name, cls.__name__, registry[name].__name__)\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mregistry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigurationError\u001b[0m: 'Cannot register event2mind as Model; name already in use for Event2Mind'"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy\n",
    "from overrides import overrides\n",
    "\n",
    "import torch\n",
    "from torch.nn import Module, ModuleDict\n",
    "from torch.nn.modules.rnn import GRUCell\n",
    "from torch.nn.modules.linear import Linear\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from allennlp.common.util import START_SYMBOL, END_SYMBOL\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.modules import Seq2VecEncoder, TextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "# from allennlp.models.model import Model\n",
    "from allennlp.nn.beam_search import BeamSearch\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.training.metrics import UnigramRecall\n",
    "\n",
    "\n",
    "@Model.register(\"event2mind\")\n",
    "class Event2Mind(Model):\n",
    "    \"\"\"\n",
    "    This ``Event2Mind`` class is a :class:`Model` which takes an event\n",
    "    sequence, encodes it, and then uses the encoded representation to decode\n",
    "    several mental state sequences.\n",
    "    It is based on `the paper by Rashkin et al.\n",
    "    <https://www.semanticscholar.org/paper/Event2Mind/b89f8a9b2192a8f2018eead6b135ed30a1f2144d>`_\n",
    "    Parameters\n",
    "    ----------\n",
    "    vocab : ``Vocabulary``, required\n",
    "        Vocabulary containing source and target vocabularies. They may be under the same namespace\n",
    "        (``tokens``) or the target tokens can have a different namespace, in which case it needs to\n",
    "        be specified as ``target_namespace``.\n",
    "    source_embedder : ``TextFieldEmbedder``, required\n",
    "        Embedder for source side sequences.\n",
    "    embedding_dropout: float, required\n",
    "        The amount of dropout to apply after the source tokens have been embedded.\n",
    "    encoder : ``Seq2VecEncoder``, required\n",
    "        The encoder of the \"encoder/decoder\" model.\n",
    "    max_decoding_steps : int, required\n",
    "        Length of decoded sequences.\n",
    "    beam_size : int, optional (default = 10)\n",
    "        The width of the beam search.\n",
    "    target_names: ``List[str]``, optional, (default = ['xintent', 'xreact', 'oreact'])\n",
    "        Names of the target fields matching those in the ``Instance`` objects.\n",
    "    target_namespace : str, optional (default = 'tokens')\n",
    "        If the target side vocabulary is different from the source side's, you need to specify the\n",
    "        target's namespace here. If not, we'll assume it is \"tokens\", which is also the default\n",
    "        choice for the source side, and this might cause them to share vocabularies.\n",
    "    target_embedding_dim : int, optional (default = source_embedding_dim)\n",
    "        You can specify an embedding dimensionality for the target side. If not, we'll use the same\n",
    "        value as the source embedder's.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 vocab: Vocabulary,\n",
    "                 source_embedder: TextFieldEmbedder,\n",
    "                 embedding_dropout: float,\n",
    "                 encoder: Seq2VecEncoder,\n",
    "                 max_decoding_steps: int,\n",
    "                 beam_size: int = 10,\n",
    "                 target_names: List[str] = None,\n",
    "                 target_namespace: str = \"tokens\",\n",
    "                 target_embedding_dim: int = None) -> None:\n",
    "        super().__init__(vocab)\n",
    "        target_names = target_names or [\"xintent\", \"xreact\", \"oreact\"]\n",
    "\n",
    "        # Note: The original tweaks the embeddings for \"personx\" to be the mean\n",
    "        # across the embeddings for \"he\", \"she\", \"him\" and \"her\". Similarly for\n",
    "        # \"personx's\" and so forth. We could consider that here as a well.\n",
    "        self._source_embedder = source_embedder\n",
    "        self._embedding_dropout = nn.Dropout(embedding_dropout)\n",
    "        self._encoder = encoder\n",
    "        self._max_decoding_steps = max_decoding_steps\n",
    "        self._target_namespace = target_namespace\n",
    "\n",
    "        # We need the start symbol to provide as the input at the first timestep of decoding, and\n",
    "        # end symbol as a way to indicate the end of the decoded sequence.\n",
    "        self._start_index = self.vocab.get_token_index(START_SYMBOL, self._target_namespace)\n",
    "        self._end_index = self.vocab.get_token_index(END_SYMBOL, self._target_namespace)\n",
    "        # Warning: The different decoders share a vocabulary! This may be\n",
    "        # counterintuitive, but consider the case of xreact and oreact. A\n",
    "        # reaction of \"happy\" could easily apply to both the subject of the\n",
    "        # event and others. This could become less appropriate as more decoders\n",
    "        # are added.\n",
    "        num_classes = self.vocab.get_vocab_size(self._target_namespace)\n",
    "        # Decoder output dim needs to be the same as the encoder output dim since we initialize the\n",
    "        # hidden state of the decoder with that of the final hidden states of the encoder.\n",
    "        self._decoder_output_dim = self._encoder.get_output_dim()\n",
    "        target_embedding_dim = target_embedding_dim or self._source_embedder.get_output_dim()\n",
    "\n",
    "        self._states = ModuleDict()\n",
    "        for name in target_names:\n",
    "            self._states[name] = StateDecoder(\n",
    "                    num_classes,\n",
    "                    target_embedding_dim,\n",
    "                    self._decoder_output_dim\n",
    "            )\n",
    "\n",
    "        self._beam_search = BeamSearch(\n",
    "                self._end_index,\n",
    "                beam_size=beam_size,\n",
    "                max_steps=max_decoding_steps\n",
    "        )\n",
    "\n",
    "    def _update_recall(self,\n",
    "                       all_top_k_predictions: torch.Tensor,\n",
    "                       target_tokens: Dict[str, torch.LongTensor],\n",
    "                       target_recall: UnigramRecall) -> None:\n",
    "        targets = target_tokens[\"tokens\"]\n",
    "        target_mask = get_text_field_mask(target_tokens)\n",
    "        # See comment in _get_loss.\n",
    "        # TODO(brendanr): Do we need contiguous here?\n",
    "        relevant_targets = targets[:, 1:].contiguous()\n",
    "        relevant_mask = target_mask[:, 1:].contiguous()\n",
    "        target_recall(\n",
    "                all_top_k_predictions,\n",
    "                relevant_targets,\n",
    "                relevant_mask,\n",
    "                self._end_index\n",
    "        )\n",
    "\n",
    "    def _get_num_decoding_steps(self,\n",
    "                                target_tokens: Optional[Dict[str, torch.LongTensor]]) -> int:\n",
    "        if target_tokens:\n",
    "            targets = target_tokens[\"tokens\"]\n",
    "            target_sequence_length = targets.size()[1]\n",
    "            # The last input from the target is either padding or the end\n",
    "            # symbol.  Either way, we don't have to process it. (To be clear,\n",
    "            # we do still output and compare against the end symbol, but there\n",
    "            # is no need to take the end symbol as input to the decoder.)\n",
    "            return target_sequence_length - 1\n",
    "        else:\n",
    "            return self._max_decoding_steps\n",
    "\n",
    "    @overrides\n",
    "    def forward(self,  # type: ignore\n",
    "                source: Dict[str, torch.LongTensor],\n",
    "                **target_tokens: Dict[str, Dict[str, torch.LongTensor]]) -> Dict[str, torch.Tensor]:\n",
    "        # pylint: disable=arguments-differ\n",
    "        \"\"\"\n",
    "        Decoder logic for producing the target sequences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        source : ``Dict[str, torch.LongTensor]``\n",
    "            The output of ``TextField.as_array()`` applied on the source\n",
    "            ``TextField``. This will be passed through a ``TextFieldEmbedder``\n",
    "            and then through an encoder.\n",
    "        target_tokens : ``Dict[str, Dict[str, torch.LongTensor]]``:\n",
    "            Dictionary from name to output of ``Textfield.as_array()`` applied\n",
    "            on target ``TextField``. We assume that the target tokens are also\n",
    "            represented as a ``TextField``.\n",
    "        \"\"\"\n",
    "        # (batch_size, input_sequence_length, embedding_dim)\n",
    "        embedded_input = self._embedding_dropout(self._source_embedder(source))\n",
    "        source_mask = get_text_field_mask(source)\n",
    "        # (batch_size, encoder_output_dim)\n",
    "        final_encoder_output = self._encoder(embedded_input, source_mask)\n",
    "        output_dict = {}\n",
    "\n",
    "        # Perform greedy search so we can get the loss.\n",
    "        if target_tokens:\n",
    "            if target_tokens.keys() != self._states.keys():\n",
    "                target_only = target_tokens.keys() - self._states.keys()\n",
    "                states_only = self._states.keys() - target_tokens.keys()\n",
    "                raise Exception(\"Mismatch between target_tokens and self._states. Keys in \" +\n",
    "                                f\"targets only: {target_only} Keys in states only: {states_only}\")\n",
    "            total_loss = 0\n",
    "            for name, state in self._states.items():\n",
    "                loss = self.greedy_search(\n",
    "                        final_encoder_output=final_encoder_output,\n",
    "                        target_tokens=target_tokens[name],\n",
    "                        target_embedder=state.embedder,\n",
    "                        decoder_cell=state.decoder_cell,\n",
    "                        output_projection_layer=state.output_projection_layer\n",
    "                )\n",
    "                total_loss += loss\n",
    "                output_dict[f\"{name}_loss\"] = loss\n",
    "\n",
    "            # Use mean loss (instead of the sum of the losses) to be comparable to the paper.\n",
    "            output_dict[\"loss\"] = total_loss / len(self._states)\n",
    "\n",
    "        # Perform beam search to obtain the predictions.\n",
    "        if not self.training:\n",
    "            batch_size = final_encoder_output.size()[0]\n",
    "            for name, state in self._states.items():\n",
    "                start_predictions = final_encoder_output.new_full(\n",
    "                        (batch_size,), fill_value=self._start_index, dtype=torch.long)\n",
    "                start_state = {\"decoder_hidden\": final_encoder_output}\n",
    "\n",
    "                # (batch_size, 10, num_decoding_steps)\n",
    "                all_top_k_predictions, log_probabilities = self._beam_search.search(\n",
    "                        start_predictions, start_state, state.take_step)\n",
    "\n",
    "                if target_tokens:\n",
    "                    self._update_recall(all_top_k_predictions, target_tokens[name], state.recall)\n",
    "                output_dict[f\"{name}_top_k_predictions\"] = all_top_k_predictions\n",
    "                output_dict[f\"{name}_top_k_log_probabilities\"] = log_probabilities\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "    def greedy_search(self,\n",
    "                      final_encoder_output: torch.LongTensor,\n",
    "                      target_tokens: Dict[str, torch.LongTensor],\n",
    "                      target_embedder: Embedding,\n",
    "                      decoder_cell: GRUCell,\n",
    "                      output_projection_layer: Linear) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Greedily produces a sequence using the provided ``decoder_cell``.\n",
    "        Returns the cross entropy between this sequence and ``target_tokens``.\n",
    "        Parameters\n",
    "        ----------\n",
    "        final_encoder_output : ``torch.LongTensor``, required\n",
    "            Vector produced by ``self._encoder``.\n",
    "        target_tokens : ``Dict[str, torch.LongTensor]``, required\n",
    "            The output of ``TextField.as_array()`` applied on some target ``TextField``.\n",
    "        target_embedder : ``Embedding``, required\n",
    "            Used to embed the target tokens.\n",
    "        decoder_cell: ``GRUCell``, required\n",
    "            The recurrent cell used at each time step.\n",
    "        output_projection_layer: ``Linear``, required\n",
    "            Linear layer mapping to the desired number of classes.\n",
    "        \"\"\"\n",
    "        num_decoding_steps = self._get_num_decoding_steps(target_tokens)\n",
    "        targets = target_tokens[\"tokens\"]\n",
    "        decoder_hidden = final_encoder_output\n",
    "        step_logits = []\n",
    "        for timestep in range(num_decoding_steps):\n",
    "            # See https://github.com/allenai/allennlp/issues/1134.\n",
    "            input_choices = targets[:, timestep]\n",
    "            decoder_input = target_embedder(input_choices)\n",
    "            decoder_hidden = decoder_cell(decoder_input, decoder_hidden)\n",
    "            # (batch_size, num_classes)\n",
    "            output_projections = output_projection_layer(decoder_hidden)\n",
    "            # list of (batch_size, 1, num_classes)\n",
    "            step_logits.append(output_projections.unsqueeze(1))\n",
    "        # (batch_size, num_decoding_steps, num_classes)\n",
    "        logits = torch.cat(step_logits, 1)\n",
    "        target_mask = get_text_field_mask(target_tokens)\n",
    "        return self._get_loss(logits, targets, target_mask)\n",
    "\n",
    "    def greedy_predict(self,\n",
    "                       final_encoder_output: torch.LongTensor,\n",
    "                       target_embedder: Embedding,\n",
    "                       decoder_cell: GRUCell,\n",
    "                       output_projection_layer: Linear) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Greedily produces a sequence using the provided ``decoder_cell``.\n",
    "        Returns the predicted sequence.\n",
    "        Parameters\n",
    "        ----------\n",
    "        final_encoder_output : ``torch.LongTensor``, required\n",
    "            Vector produced by ``self._encoder``.\n",
    "        target_embedder : ``Embedding``, required\n",
    "            Used to embed the target tokens.\n",
    "        decoder_cell: ``GRUCell``, required\n",
    "            The recurrent cell used at each time step.\n",
    "        output_projection_layer: ``Linear``, required\n",
    "            Linear layer mapping to the desired number of classes.\n",
    "        \"\"\"\n",
    "        num_decoding_steps = self._max_decoding_steps\n",
    "        decoder_hidden = final_encoder_output\n",
    "        batch_size = final_encoder_output.size()[0]\n",
    "        predictions = [final_encoder_output.new_full(\n",
    "                (batch_size,), fill_value=self._start_index, dtype=torch.long\n",
    "        )]\n",
    "        for _ in range(num_decoding_steps):\n",
    "            input_choices = predictions[-1]\n",
    "            decoder_input = target_embedder(input_choices)\n",
    "            decoder_hidden = decoder_cell(decoder_input, decoder_hidden)\n",
    "            # (batch_size, num_classes)\n",
    "            output_projections = output_projection_layer(decoder_hidden)\n",
    "            class_probabilities = F.softmax(output_projections, dim=-1)\n",
    "            _, predicted_classes = torch.max(class_probabilities, 1)\n",
    "            predictions.append(predicted_classes)\n",
    "        all_predictions = torch.cat([ps.unsqueeze(1) for ps in predictions], 1)\n",
    "        # Drop start symbol and return.\n",
    "        return all_predictions[:, 1:]\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_loss(logits: torch.LongTensor,\n",
    "                  targets: torch.LongTensor,\n",
    "                  target_mask: torch.LongTensor) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Takes logits (unnormalized outputs from the decoder) of size (batch_size,\n",
    "        num_decoding_steps, num_classes), target indices of size (batch_size, num_decoding_steps+1)\n",
    "        and corresponding masks of size (batch_size, num_decoding_steps+1) steps and computes cross\n",
    "        entropy loss while taking the mask into account.\n",
    "        The length of ``targets`` is expected to be greater than that of ``logits`` because the\n",
    "        decoder does not need to compute the output corresponding to the last timestep of\n",
    "        ``targets``. This method aligns the inputs appropriately to compute the loss.\n",
    "        During training, we want the logit corresponding to timestep i to be similar to the target\n",
    "        token from timestep i + 1. That is, the targets should be shifted by one timestep for\n",
    "        appropriate comparison.  Consider a single example where the target has 3 words, and\n",
    "        padding is to 7 tokens.\n",
    "           The complete sequence would correspond to <S> w1  w2  w3  <E> <P> <P>\n",
    "           and the mask would be                     1   1   1   1   1   0   0\n",
    "           and let the logits be                     l1  l2  l3  l4  l5  l6\n",
    "        We actually need to compare:\n",
    "           the sequence           w1  w2  w3  <E> <P> <P>\n",
    "           with masks             1   1   1   1   0   0\n",
    "           against                l1  l2  l3  l4  l5  l6\n",
    "           (where the input was)  <S> w1  w2  w3  <E> <P>\n",
    "        \"\"\"\n",
    "        relevant_targets = targets[:, 1:].contiguous()  # (batch_size, num_decoding_steps)\n",
    "        relevant_mask = target_mask[:, 1:].contiguous()  # (batch_size, num_decoding_steps)\n",
    "        loss = sequence_cross_entropy_with_logits(logits, relevant_targets, relevant_mask)\n",
    "        return loss\n",
    "\n",
    "    def decode_all(self, predicted_indices: torch.Tensor) -> List[List[str]]:\n",
    "        if not isinstance(predicted_indices, numpy.ndarray):\n",
    "            predicted_indices = predicted_indices.detach().cpu().numpy()\n",
    "        all_predicted_tokens = []\n",
    "        for indices in predicted_indices:\n",
    "            indices = list(indices)\n",
    "            # Collect indices till the first end_symbol\n",
    "            if self._end_index in indices:\n",
    "                indices = indices[:indices.index(self._end_index)]\n",
    "            predicted_tokens = [self.vocab.get_token_from_index(x, namespace=self._target_namespace)\n",
    "                                for x in indices]\n",
    "            all_predicted_tokens.append(predicted_tokens)\n",
    "        return all_predicted_tokens\n",
    "\n",
    "    @overrides\n",
    "    def decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, List[List[str]]]:\n",
    "        \"\"\"\n",
    "        This method overrides ``Model.decode``, which gets called after ``Model.forward``, at test\n",
    "        time, to finalize predictions. The logic for the decoder part of the encoder-decoder lives\n",
    "        within the ``forward`` method.\n",
    "        This method trims the output predictions to the first end symbol, replaces indices with\n",
    "        corresponding tokens, and adds fields for the tokens to the ``output_dict``.\n",
    "        \"\"\"\n",
    "        for name in self._states:\n",
    "            top_k_predicted_indices = output_dict[f\"{name}_top_k_predictions\"][0]\n",
    "            output_dict[f\"{name}_top_k_predicted_tokens\"] = [self.decode_all(top_k_predicted_indices)]\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "    @overrides\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        all_metrics = {}\n",
    "        # Recall@10 needs beam search which doesn't happen during training.\n",
    "        if not self.training:\n",
    "            for name, state in self._states.items():\n",
    "                all_metrics[name] = state.recall.get_metric(reset=reset)\n",
    "        return all_metrics\n",
    "\n",
    "\n",
    "class StateDecoder(Module):\n",
    "    # pylint: disable=abstract-method\n",
    "    \"\"\"\n",
    "    Simple struct-like class for internal use.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_classes: int,\n",
    "                 input_dim: int,\n",
    "                 output_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.embedder = Embedding(num_classes, input_dim)\n",
    "        self.decoder_cell = GRUCell(input_dim, output_dim)\n",
    "        self.output_projection_layer = Linear(output_dim, num_classes)\n",
    "        self.recall = UnigramRecall()\n",
    "\n",
    "    def take_step(self,\n",
    "                  last_predictions: torch.Tensor,\n",
    "                  state: Dict[str, torch.Tensor]) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        decoder_hidden = state[\"decoder_hidden\"]\n",
    "        decoder_input = self.embedder(last_predictions)\n",
    "        decoder_hidden = self.decoder_cell(decoder_input, decoder_hidden)\n",
    "        state[\"decoder_hidden\"] = decoder_hidden\n",
    "        output_projections = self.output_projection_layer(decoder_hidden)\n",
    "        class_log_probabilities = F.log_softmax(output_projections, dim=-1)\n",
    "        return class_log_probabilities, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/06/2018 00:33:49 - INFO - __main__ -   loading archive file data/event22mind.tar.gz\n",
      "12/06/2018 00:33:49 - INFO - __main__ -   extracting archive file data/event22mind.tar.gz to temp dir /tmp/tmpctz31zzp\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   vocabulary.type = default\n",
      "12/06/2018 00:33:50 - INFO - allennlp.data.vocabulary -   Loading token dictionary from /tmp/tmpctz31zzp/vocabulary.\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.model.Model'> from params {'embedding_dropout': 0.2, 'encoder': {'bidirectional': True, 'hidden_size': 50, 'input_size': 300, 'num_layers': 1, 'type': 'gru'}, 'max_decoding_steps': 10, 'source_embedder': {'token_embedders': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}}}, 'target_namespace': 'target_tokens', 'type': 'event2mind'} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f818ffd4438>}\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.type = event2mind\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.event2mind.Event2Mind'> from params {'embedding_dropout': 0.2, 'encoder': {'bidirectional': True, 'hidden_size': 50, 'input_size': 300, 'num_layers': 1, 'type': 'gru'}, 'max_decoding_steps': 10, 'source_embedder': {'token_embedders': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}}}, 'target_namespace': 'target_tokens'} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f818ffd4438>}\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding', 'vocab_namespace': 'source_tokens'}}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f818ffd4438>}\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.type = basic\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.embedder_to_indexer_map = None\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.allow_unmatched_keys = False\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 300, 'trainable': False, 'type': 'embedding', 'vocab_namespace': 'source_tokens'} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f818ffd4438>}\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.type = embedding\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.num_embeddings = None\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.vocab_namespace = source_tokens\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.embedding_dim = 300\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.pretrained_file = None\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.projection_dim = None\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.trainable = False\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.padding_index = None\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.max_norm = None\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.norm_type = 2.0\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.source_embedder.token_embedders.tokens.sparse = False\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.embedding_dropout = 0.2\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'bidirectional': True, 'hidden_size': 50, 'input_size': 300, 'num_layers': 1, 'type': 'gru'} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f818ffd4438>}\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.encoder.type = gru\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.encoder.batch_first = True\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.encoder.bidirectional = True\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.encoder.hidden_size = 50\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.encoder.input_size = 300\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.encoder.num_layers = 1\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.encoder.batch_first = True\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.max_decoding_steps = 10\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.beam_size = 10\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.target_names = None\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.target_namespace = target_tokens\n",
      "12/06/2018 00:33:50 - INFO - allennlp.common.params -   model.target_embedding_dim = None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Event2Mind:\n\tMissing key(s) in state_dict: \"_states.xintent.embedder.weight\", \"_states.xintent.decoder_cell.weight_ih\", \"_states.xintent.decoder_cell.weight_hh\", \"_states.xintent.decoder_cell.bias_ih\", \"_states.xintent.decoder_cell.bias_hh\", \"_states.xintent.output_projection_layer.weight\", \"_states.xintent.output_projection_layer.bias\", \"_states.xreact.embedder.weight\", \"_states.xreact.decoder_cell.weight_ih\", \"_states.xreact.decoder_cell.weight_hh\", \"_states.xreact.decoder_cell.bias_ih\", \"_states.xreact.decoder_cell.bias_hh\", \"_states.xreact.output_projection_layer.weight\", \"_states.xreact.output_projection_layer.bias\", \"_states.oreact.embedder.weight\", \"_states.oreact.decoder_cell.weight_ih\", \"_states.oreact.decoder_cell.weight_hh\", \"_states.oreact.decoder_cell.bias_ih\", \"_states.oreact.decoder_cell.bias_hh\", \"_states.oreact.output_projection_layer.weight\", \"_states.oreact.output_projection_layer.bias\". \n\tUnexpected key(s) in state_dict: \"xintent_embedder.weight\", \"xintent_decoder_cell.weight_ih\", \"xintent_decoder_cell.weight_hh\", \"xintent_decoder_cell.bias_ih\", \"xintent_decoder_cell.bias_hh\", \"xintent_output_project_layer.weight\", \"xintent_output_project_layer.bias\", \"xreact_embedder.weight\", \"xreact_decoder_cell.weight_ih\", \"xreact_decoder_cell.weight_hh\", \"xreact_decoder_cell.bias_ih\", \"xreact_decoder_cell.bias_hh\", \"xreact_output_project_layer.weight\", \"xreact_output_project_layer.bias\", \"oreact_embedder.weight\", \"oreact_decoder_cell.weight_ih\", \"oreact_decoder_cell.weight_hh\", \"oreact_decoder_cell.bias_ih\", \"oreact_decoder_cell.bias_hh\", \"oreact_output_project_layer.weight\", \"oreact_output_project_layer.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-50fa5bbe5e25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# from allennlp.models.archival import load_archive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/event22mind.tar.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-fe78811f9055>\u001b[0m in \u001b[0;36mload_archive\u001b[0;34m(archive_file, cuda_device, overrides, weights_file)\u001b[0m\n\u001b[1;32m    150\u001b[0m                        \u001b[0mweights_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                        \u001b[0mserialization_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserialization_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                        cuda_device=cuda_device)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtempdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, config, serialization_dir, weights_file, cuda_device)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# This allows subclasses of Model to override _load.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mby_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialization_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/allennlp/models/model.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(cls, config, serialization_dir, weights_file, cuda_device)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mmodel_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Force model to cpu or gpu, as appropriate, to make sure that the embeddings are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 719\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Event2Mind:\n\tMissing key(s) in state_dict: \"_states.xintent.embedder.weight\", \"_states.xintent.decoder_cell.weight_ih\", \"_states.xintent.decoder_cell.weight_hh\", \"_states.xintent.decoder_cell.bias_ih\", \"_states.xintent.decoder_cell.bias_hh\", \"_states.xintent.output_projection_layer.weight\", \"_states.xintent.output_projection_layer.bias\", \"_states.xreact.embedder.weight\", \"_states.xreact.decoder_cell.weight_ih\", \"_states.xreact.decoder_cell.weight_hh\", \"_states.xreact.decoder_cell.bias_ih\", \"_states.xreact.decoder_cell.bias_hh\", \"_states.xreact.output_projection_layer.weight\", \"_states.xreact.output_projection_layer.bias\", \"_states.oreact.embedder.weight\", \"_states.oreact.decoder_cell.weight_ih\", \"_states.oreact.decoder_cell.weight_hh\", \"_states.oreact.decoder_cell.bias_ih\", \"_states.oreact.decoder_cell.bias_hh\", \"_states.oreact.output_projection_layer.weight\", \"_states.oreact.output_projection_layer.bias\". \n\tUnexpected key(s) in state_dict: \"xintent_embedder.weight\", \"xintent_decoder_cell.weight_ih\", \"xintent_decoder_cell.weight_hh\", \"xintent_decoder_cell.bias_ih\", \"xintent_decoder_cell.bias_hh\", \"xintent_output_project_layer.weight\", \"xintent_output_project_layer.bias\", \"xreact_embedder.weight\", \"xreact_decoder_cell.weight_ih\", \"xreact_decoder_cell.weight_hh\", \"xreact_decoder_cell.bias_ih\", \"xreact_decoder_cell.bias_hh\", \"xreact_output_project_layer.weight\", \"xreact_output_project_layer.bias\", \"oreact_embedder.weight\", \"oreact_decoder_cell.weight_ih\", \"oreact_decoder_cell.weight_hh\", \"oreact_decoder_cell.bias_ih\", \"oreact_decoder_cell.bias_hh\", \"oreact_output_project_layer.weight\", \"oreact_output_project_layer.bias\". "
     ]
    }
   ],
   "source": [
    "# from allennlp.models.archival import load_archive\n",
    "archive = load_archive('data/event22mind.tar.gz', cuda_device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor.from_archive(archive, 'event2mind')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
